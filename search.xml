<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>tiest&gt;</title>
      <link href="/2023/07/17/%E5%B7%A5%E4%BD%9C%E6%97%A5%E5%BF%97log/"/>
      <url>/2023/07/17/%E5%B7%A5%E4%BD%9C%E6%97%A5%E5%BF%97log/</url>
      
        <content type="html"><![CDATA[<p>6.5-7.5<br>整理并阅读llama模型文章 比较优缺点<br>寻找低成本模型</p><p>LLaMA</p><p>Accelerating LLaMA with Fabric: A Comprehensive Guide to Training and Fine-Tuning LLaMA：<a href="https://lightning.ai/pages/community/tutorial/accelerating-llama-with-fabric-a-comprehensive-guide-to-training-and-fine-tuning-llama/">https://lightning.ai/pages/community/tutorial/accelerating-llama-with-fabric-a-comprehensive-guide-to-training-and-fine-tuning-llama/</a></p><p>LLaMA-Adapter: Efficient Fine-tuning of LLaMA 🚀：<a href="https://github.com/ZrrSkywalker/LLaMA-Adapter">https://github.com/ZrrSkywalker/LLaMA-Adapter</a></p><p>StackLLaMA: A hands-on guide to train LLaMA with RLHF：<a href="https://huggingface.co/blog/stackllama">https://huggingface.co/blog/stackllama</a></p><p>LLaMA github repo：<a href="https://github.com/facebookresearch/llama">https://github.com/facebookresearch/llama</a><br>尝试huggingface使用llama小参数版本</p><p>准备代码 准备数据集 上传数据集 数据集上传服务器需18h 阅读代码 阅读部署文档<br>colab数据上传失败 autodl服务器环境依赖解决失败 尝试不同环境 本地部署llama-7B成功 模型返回结果不稳定<br>偶有成功的返回但是效果很差<br>merge ReadON_Linea_Profile.md to linea repo<br>针对llama进行本地报错问题细节处理学习</p><p>解决报错问题<br>解决数据传输问题<br>学习lit-llam<br>try:获取数据 数据预处理 构建新数据<br>except: figure out how to do that<br>  获取小规模数据集 预处理 文本处理 删去无意义的词句<br> 文本分割 构建json文件<br> 微调试错 修改finetune.py 报错 stack overflow及gpt无法协助处理 推测是数据量过小的问题<br> 获取更多数据<br>获取数据时每个contentid对应内容不一样 有些Nonetype及其他异常需手动测试处理<br>循环测试异常 捕获处理异常 修正数据集<br>获取3万条数据集</p><p>微调模型 效果不容乐观<br>修正数据集 手动寻找影响模型分数的重要因素 编写脚本去除这些元素<br>继续微调 不断针对数个问题观察是否性能有提升<br>详细剖析prepared data,generate adpater, fine-tune adapater<br>清洗数据 尝试不同prompt效果<br>调整参数 重跑模型 效果有所提升<br>保留微调的参数<br>修改代码 调试模型<br>寻找生成式模型评价指标<br>尝试使用self-insturct<br>use gpt to do the summary, which makes our data become more precise. I wish<br>it can more or less improve the data, then improve the performance of the model<br>测试对比gpt4和bard回答效果</p><p>调试bard api<br>解决部分报错<br>提出issue</p><h3 id="Issues-when-running-the-bard-chat"><a href="#Issues-when-running-the-bard-chat" class="headerlink" title="Issues when running the bard chat"></a>Issues when running the bard chat</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">from bardapi import ChatBard</span><br><span class="line">  </span><br><span class="line">chat = ChatBard(token=token,timeout=30, language=&#x27;en&#x27;)</span><br><span class="line">chat.start()</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>Error msg:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">---------------------------------------------------------------------------</span><br><span class="line">KeyError                                  Traceback (most recent call last)</span><br><span class="line">/var/folders/y8/lsp6my6s0699tykr6ghm_my80000gn/T/ipykernel_51118/1340303370.py in </span><br><span class="line">      2 </span><br><span class="line">      3 chat = ChatBard(token=token,timeout=30, language=&#x27;en&#x27;)</span><br><span class="line">----&gt; 4 chat.start()</span><br><span class="line"></span><br><span class="line">/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/bardapi/chat.py in start(self)</span><br><span class="line">     95             response = self.bard.get_answer(user_input)</span><br><span class="line">     96 </span><br><span class="line">---&gt; 97         if response.get(&quot;images&quot;):</span><br><span class="line">     98              print(f&quot;&#123;Fore.BLUE&#125;&#123;Style.BRIGHT&#125;Chatbot: &#123;response[&#x27;content&#x27;]&#125; \n\n Image links: &#123;response[&#x27;images&#x27;]&#125;&#123;Fore.RESET&#125;&#123;Style.RESET_ALL&#125;&quot;)</span><br><span class="line">     99         else:</span><br><span class="line"></span><br><span class="line">KeyError: &#x27;images&#x27;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>I was trying to modify the code in the python module ‘bardapi’ chat.py, you can find where is your module by run this:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">import bardapi</span><br><span class="line">print(bardapi.__file__)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>but it doesn’t work since the module seems always stay at the original version. Then even if I tried the code below, the error still remains.</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">import importlib</span><br><span class="line">import bardapi</span><br><span class="line"># Make changes to my_module.py</span><br><span class="line"></span><br><span class="line"># Reload the module</span><br><span class="line">importlib.reload(bardapi)</span><br></pre></td></tr></table></figure><p>Then I requested an issue on github. It has been fixed in the updated version.<br><img src="/issue1.png" alt="the github issue img"></p><p>完成ReadON QA bot雏形 预计本周内完成 实现top100 feed 实现用户界面交互<br>11<br>12<br>9<br>9<br>8<br>10<br>9<br>10<br>12<br>12<br>10<br>10<br>8<br>8<br>8<br>8<br>7<br>6<br>9<br>8<br>5<br>7<br>4<br>8<br>8<br>9<br>7<br>4<br>6<br>10<br>9</p><p>7.6-8.5</p><p>尝试使用三元组形式构建数据，调用api接口进行实体关系抽取，后先尝试采用embedding实现文章索引<br>问题：不够精准 定位：相关文章没有不存在于数据集之中 执行：添加更多文章进行embedding<br>处理数据集，，构建prompt，代码实现demo<br>测试统计我们的数据在gpt token消费的预估额度<br><img src="/%E5%B7%A5%E4%BD%9C%E6%97%A5%E5%BF%97log/log1.png" alt="工作日志log"></p><p>问题：先测试readon项目 执行：重新获取数据集</p><p>测试波哥说的数个问题，问题集合：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># questions :</span><br><span class="line"></span><br><span class="line"># who is the investor of ReadON?</span><br><span class="line"># how does pick work on ReadON?</span><br><span class="line"># what is the relationship between ReadON and conflux?</span><br><span class="line"># 1. readon这个项目最近的活动是什么？</span><br><span class="line"># 2. readon 最近的活跃度如何？</span><br><span class="line"># 3. 我应该最近参加readon 什么活动</span><br></pre></td></tr></table></figure><p>问题：有些问题会因为未知因素response error 定位：网络问题&#x2F;访问频率</p><p>新数据集效果显著：能够较好的回答关系问题，比如readon和conflux的关系，能够提到合作的一些东西，比如card mint相关信息，表示我们的索引能够提取到相应文章，也说明模型能够较好的从我们的feed里学习到有用的东西</p><p>问题：网络不稳定 代理问题  执行：借用同学vpn进行测试，测试了7个，每个订阅的每个节点都进行了测试，除了非可用地区，效果不佳，目前使用美国和台湾省代理的稳定性较好 查看网络代理的相关文章，尝试添加代理内核重构代码</p><p>问题：相应速度较慢 定位：索引时间+bard处理文章的时间加起来太长 执行：尝试先精炼文章内容再feed，效果不佳，gpt无法识别一些关键信息，不够精炼 执行2:尝试使用其他的索引方式ing 执行3: 找到一部分原因是bard回答问题的stream特点造成了返回结果是一次性呈现在用户面前的 思考如何把流式改成real-time</p><p>提高timeout使得响应之前数据能够得到充分的处理</p><p>7<br>8<br>7<br>8<br>9<br>6<br>8<br>4<br>8<br>10<br>9<br>5</p>]]></content>
      
      
      <categories>
          
          <category> Papers </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Papers </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Paper notes about &lt;Are Large Language Models Really Good Logical Reasoners?&gt;</title>
      <link href="/2023/07/09/Paper%20notes%20about%20are%20LLM%20really%20logic/"/>
      <url>/2023/07/09/Paper%20notes%20about%20are%20LLM%20really%20logic/</url>
      
        <content type="html"><![CDATA[<h1 id="Paper-Are-Large-Language-Models-Really-Good-Logical-Reasoners"><a href="#Paper-Are-Large-Language-Models-Really-Good-Logical-Reasoners" class="headerlink" title="Paper: Are Large Language Models Really Good Logical Reasoners?"></a>Paper: Are Large Language Models Really Good Logical Reasoners?</h1><p>link:<a href="https://arxiv.org/abs/2306.09841">arxiv</a></p><p>Authors’Info:<br>Fangzhi Xu1,2*, Qika Lin1,2*, Jiawei Han1,3, Tianzhe Zhao1,3, Jun Liu2,3†, Erik Cambria4 1 School of Computer Science and Techonology, Xi’an Jiaotong University 2 Shaanxi Provincial Key Laboratory of Big Data Knowledge Engineering 3 National Engineering Lab for Big Data Analytics 4 School of Computer Science and Engineering, Nanyang Technological University <a href="mailto:&#x4c;&#x65;&#x6f;&#x39;&#x38;&#49;&#49;&#x30;&#x36;&#64;&#x73;&#116;&#x75;&#46;&#120;&#106;&#x74;&#117;&#46;&#x65;&#x64;&#x75;&#46;&#99;&#110;">&#x4c;&#x65;&#x6f;&#x39;&#x38;&#49;&#49;&#x30;&#x36;&#64;&#x73;&#116;&#x75;&#46;&#120;&#106;&#x74;&#117;&#46;&#x65;&#x64;&#x75;&#46;&#99;&#110;</a>, <a href="mailto:&#x71;&#x69;&#x6b;&#97;&#108;&#105;&#110;&#64;&#102;&#111;&#120;&#109;&#97;&#x69;&#108;&#46;&#99;&#x6f;&#x6d;">&#x71;&#x69;&#x6b;&#97;&#108;&#105;&#110;&#64;&#102;&#111;&#120;&#109;&#97;&#x69;&#108;&#46;&#99;&#x6f;&#x6d;</a>, <a href="mailto:&#116;&#x61;&#x72;&#x61;&#x31;&#50;&#x30;&#x38;&#x32;&#54;&#48;&#x32;&#50;&#x33;&#64;&#115;&#x74;&#x75;&#x2e;&#120;&#106;&#x74;&#117;&#x2e;&#x65;&#100;&#117;&#46;&#99;&#x6e;">&#116;&#x61;&#x72;&#x61;&#x31;&#50;&#x30;&#x38;&#x32;&#54;&#48;&#x32;&#50;&#x33;&#64;&#115;&#x74;&#x75;&#x2e;&#120;&#106;&#x74;&#117;&#x2e;&#x65;&#100;&#117;&#46;&#99;&#x6e;</a>, <a href="mailto:&#122;&#116;&#122;&#56;&#x37;&#x35;&#x38;&#x40;&#102;&#x6f;&#x78;&#109;&#97;&#105;&#x6c;&#x2e;&#99;&#111;&#109;">&#122;&#116;&#122;&#56;&#x37;&#x35;&#x38;&#x40;&#102;&#x6f;&#x78;&#109;&#97;&#105;&#x6c;&#x2e;&#99;&#111;&#109;</a>, <a href="mailto:&#108;&#x69;&#117;&#107;&#101;&#101;&#x6e;&#x40;&#x78;&#106;&#x74;&#117;&#x2e;&#x65;&#100;&#x75;&#46;&#x63;&#x6e;">&#108;&#x69;&#117;&#107;&#101;&#101;&#x6e;&#x40;&#x78;&#106;&#x74;&#117;&#x2e;&#x65;&#100;&#x75;&#46;&#x63;&#x6e;</a>, <a href="mailto:&#x63;&#x61;&#x6d;&#98;&#x72;&#x69;&#97;&#x40;&#110;&#x74;&#x75;&#46;&#x65;&#x64;&#117;&#46;&#x73;&#103;">&#x63;&#x61;&#x6d;&#98;&#x72;&#x69;&#97;&#x40;&#110;&#x74;&#x75;&#46;&#x65;&#x64;&#117;&#46;&#x73;&#103;</a></p><h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>该研究旨在对大型语言模型（LLM）的逻辑推理能力进行全面评估，重点是演绎，归纳和演绎推理。作者选择了十五个典型的逻辑推理数据集, 他们分别在在zero-shot, one-shot, three-shot下评估了三个代表性的LLM（text-davinci-003，ChatGPT和BARD）。此外，他们还从客观和主观的角度提出了精细的评估，包括答案和解释。他们还引入了一个具有中性内容的新数据集，以衡量LLM的逻辑推理能力。最后从六个维度绘制了逻辑推理能力图，反映了LLM的优势和劣势，并提出了未来的发展方向。</p><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>本文认为有很少工作从逻辑推理的角度对LLM进行研究，所以他们打算从几个方面去评估LLM<br>分别是deductive, inductive and abductive三种方式的的推理 区别可点此链接查看：<a href="http://factmyth.com/deductive-inductive-and-abductive-reasoning-explained/#:~:text=The%20core%20concepts%20to%20remember,guesswork%2C%20involves%20reasoning%20toward%20possible">deductive, inductive and abductive</a></p><p>所有用于评估的数据集分为4类分别是deductive, inductive, abductive and mixed-forms。其次当前评估LLM的指标不够多和全面，最多就是一些矩阵比如精确度来衡量，由于类似chatgpt这种LLM是与人交户性比较强的工具，所以需要加上一些subjective性质的指标，包括：answer accuracy, explaination correctness, explaination redundancy and explaination completeness这四种。由于LLM容易学到bias，所以很多情况下逻辑推理会受到previous bias影响，导致其不是真正的逻辑论断，因此也想从中立内容这方面对其进行一个测试。最后他们得出了一个完善的评估系统，包括六个维度，分别是Correct, Rigorous, Self-aware, Active, Oriented and No Hallucination.</p><p>本文的一些贡献，大致是探索了LLM真正的逻辑推理能力，对逻辑推理能力的评估手段进行了一个系统性的升级，提供一些精细化而不是只用objective metrics的评估维度，提供了中立内容的数据集NeuLR。</p><h2 id="Preliminary"><a href="#Preliminary" class="headerlink" title="Preliminary"></a>Preliminary</h2><p>逻辑推理简单来说就是基于给出的一些前提premise然后推理出conclusion，打个比方rule: Children of eight years old are all in primary school. • fact1&#x2F;premise1: Jordan is a child of eight years old. • fact2&#x2F;premise2: Jordan is in primary school. 这三条我们可以用其中的两条推出剩余的一条。</p><p>首先deductive reasoning，可以理解为给出大前提，再给小前提就可以得出结论，比如说所有青少年都小于20岁（不严谨）+ 我是青少年， 即可得出：我小于20岁。作者说这是自上而下的 top-down</p><p>其次inductive reasoning，也就是归纳的意思，即从特殊的现象中得出一套泛化的结论，比如说：我是人 + 有些人是雄性，那么可以得出：我有可能是雄性。不确定是因为归纳推理本身就是probabilistic，不是certain的，作者认为这是自下而上的也就是bottom-up。</p><p>最后abductive reasoning，它也是probabilistic的，就是说从rule+一个前提得到一个可能性的结论，比如说我在上学 + 所有青少年都在上学，可以得出我可能是青少年，但是并不一定，所以abductive reasoning是和inductive reasoning的“可能性”特质很像的。</p><h2 id="Evaluation-Details"><a href="#Evaluation-Details" class="headerlink" title="Evaluation Details"></a>Evaluation Details</h2><p>这部分就是文本使用的一些待评估模型，数据集和测试指标。</p><ul><li><strong>评估模型</strong></li></ul><p>首先是openai最早发布的LLM：text-davinci-003，然后是GPT-3.5-turbo，以及google的bard。</p><ul><li><strong>评估的数据集</strong></li></ul><p>本文选取了15个逻辑推理常用的数据集并将它们做了划分（因为本文有四个task）</p><ul><li><strong>评估的指标</strong></li></ul><p>有四个，我分别阐述一下</p><p><strong>Answer Correctness</strong> 看生成的回答label是否为true，在生成式任务中只要意思相同就可以了，不需要token一致。</p><p><strong>Explanation Correctness</strong> 这是一个主观的标准，就是看逻辑推理的过程中它的解释是否符合人的思维，能够合理的推断出结论</p><p><strong>Explanation Completeness</strong> 我不太明白这个，但是大致的意思是正确答案能仅通过选中的facts推断出来</p><p><strong>Explanation Redundancy</strong> 如其名就是逻辑推理的过程中被给到的facts太多了，比如说你两条facts就可以推断出这个结论但是我要用10条。</p><h2 id="Overall-Experiments"><a href="#Overall-Experiments" class="headerlink" title="Overall Experiments"></a>Overall Experiments</h2><p>实验结果的一些展示，先放图：<img src="/paper2.jpg" alt="实验图"></p><p>发现LLM在deductive reasoning方面做的比较好，inductive这方面的难度按理来说是最高的，另外few-shot上下文之间的学习并不一定能改善逻辑推理的能力，在其他非推理层面的NLP任务里反而是很有效果的。</p><h2 id="Fine-level-Evaluations"><a href="#Fine-level-Evaluations" class="headerlink" title="Fine-level Evaluations"></a>Fine-level Evaluations</h2><p>最终各个模型在四个指标评估结果如下图，图脉络清晰我就不用文字加以赘述</p><p><img src="/paper2_2.jpg" alt="paper2"></p><h2 id="Are-LLMs-Rigorous-Logical-Reasoning"><a href="#Are-LLMs-Rigorous-Logical-Reasoning" class="headerlink" title="Are LLMs Rigorous Logical Reasoning?"></a>Are LLMs Rigorous Logical Reasoning?</h2><p>思考LLM真的能严密的进行逻辑推理吗<br>引用原文的话“LLMs are best at keeping the rigorous reasoning in the abductive setting, while they are weak in the inductive setting”</p><h2 id="Are-LLMs-Self-aware-Logical-Reasoners"><a href="#Are-LLMs-Self-aware-Logical-Reasoners" class="headerlink" title="Are LLMs Self-aware Logical Reasoners?"></a>Are LLMs Self-aware Logical Reasoners?</h2><p>生成式任务中LLMs回答的冗余度还是相对分类任务来说较高的，因为模型可以从多个维度去回答，</p><p>后续都是一些问题的回答，只不过都用数据作为答案展现出来了，比较多详情可点击论文查看。</p><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>重述了一下之前强调本文使用的几个指标，衡量了几个任务，以及指出相应的逻辑推理包含的能力应该分为哪些。</p><p>最后根据结果，text-davinci-003可以在deductive 和 mixed-form模式中取得较均衡的成绩，inductive reasoning不太好，以及在abductive reasoning中lazy，从综合角度看，chatgpt表现较弱，但是它在避免幻想这个层面做的比较好，在保持理性方面做的较好，因为毕竟是chat tool，但是推理不太好。bard能力相对强，但是冗余度比较高，所以LLMs在逻辑推理能力方面还是有相应的局限性，以及现在评估逻辑推理能力的指标不够全面，有待做的事情还有很多。</p><h2 id="Future-Directions"><a href="#Future-Directions" class="headerlink" title="Future Directions"></a>Future Directions</h2><p>对未来的一些展望，比如加强薄弱点，也就是inductive reasoning的能力，提高LLM的认知边界，也就是老师说的cognitive science层面的东西，需要self-aware的能力，以及要适应真实世界的一些场景的问题等等。</p><h2 id="dataset"><a href="#dataset" class="headerlink" title="dataset"></a>dataset</h2><p>totally there are 15 datasets: and I’ll summarize how are they constructed<br><img src="/paper2_3.jpg"></p><ul><li><p>部分数据集是在已发表研究的基础上构建的。比如LogiQA 1.0和2.0是在LogiQA的基础上新增了样本扩充而来。</p></li><li><p>部分数据集直接引用了已发表的研究论文中的数据集,比如bAbI-15和16、α-NLI等。</p></li><li><p>部分数据集像LogiQA2NLI是论文作者通过从其他数据集中筛选样本构建的。</p></li></ul><p>下方列举一些数据集的样本： 比如说在logicQA dataset里<br><img src="/paper2_4.jpg"><br>训练集验证集和测试集中每一条数据都是由空行+正确选择+背景+问题+四个选项构成<br>可以看出背景描述中都使用了逻辑连接词比如第一条‘so’，旨在训练模型逻辑推理的能力<br>下载详细数据可点击：<a href="https://raw.githubusercontent.com/lgw863/LogiQA-dataset/master/Train.txt">github&#x2F;repo</a></p><p>构建的方法揣测：</p><ul><li>基于语料库从大规模语料库中抽取自然语言语句，使用自然语言推理模型预测句子间的逻辑关系,生成句子对人工检查过滤关系预测错误的样本</li><li>基于知识图谱从知识图谱中提取实体和事实三元组,转换为自然语言描述，抽取且转换两三元组,构建含有逻辑关系的句子对人工检查过滤无意义的样本</li></ul><h2 id="关于四个指标如何衡量及具体例子"><a href="#关于四个指标如何衡量及具体例子" class="headerlink" title="关于四个指标如何衡量及具体例子"></a>关于四个指标如何衡量及具体例子</h2><ul><li>Answer Correctness:</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">前提:猫和狮子都属于猫科动物</span><br><span class="line">问题:老虎属于猫科动物吗?</span><br><span class="line">回答:是</span><br><span class="line"></span><br><span class="line">判断:老虎属于猫科,回答正确</span><br></pre></td></tr></table></figure><p>可以由模型自动判断生成回答的正确性,与ground truth对比。</p><ul><li>Explanation Correctness:</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">前提:兔子是噪音动物,噪音动物都是扁平头骨动物</span><br><span class="line">问题:兔子是否扁平头骨?</span><br><span class="line">解释:兔子属于噪音动物,噪音动物属于扁平头骨动物,所以可以推断兔子是扁平头骨。</span><br><span class="line"></span><br><span class="line">判断:基于知识图谱关系的合理解释。</span><br></pre></td></tr></table></figure><p>这里可能是作者团队人为根据解释是否符合人类逻辑推理进行打分，因为该评价指标为subjective，但是在论文中我没有找到明确说明的地方。</p><ul><li>Explanation Redundancy:</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">前提:猫是肉食性动物,猫吃老鼠,猫有尖锐爪牙。</span><br><span class="line">问题:猫的食物是什么?</span><br><span class="line">解释:猫是肉食性动物,猫是肉食性动物,猫吃老鼠......</span><br><span class="line"></span><br><span class="line">判断:重复提到“猫是肉食性动物”,存在冗余</span><br></pre></td></tr></table></figure><p>可以通过自动方法检测重复前提,进行冗余判断。<br>例如基于注意力机制或匹配网络判定重复。</p><ul><li>Explanation Completeness:</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">前提:鲸鱼属于海洋哺乳动物</span><br><span class="line">问题:鲸鱼的生存环境是?</span><br><span class="line">解释:鲸鱼属于哺乳动物。</span><br><span class="line"></span><br><span class="line">判断:缺少“海洋”关键信息,解释不完整。</span><br></pre></td></tr></table></figure><p>可以使用问答模型或信息检索自动判断解释是否可从前提完整推导。</p><h2 id="与HRM的联系"><a href="#与HRM的联系" class="headerlink" title="与HRM的联系"></a>与HRM的联系</h2><h3 id="区别"><a href="#区别" class="headerlink" title="区别:"></a>区别:</h3><p>研究动机不同</p><ul><li>“Are LLM Really Logical Reasoners”专注评估LLM的逻辑推理能力</li><li>“Human Reasoning Module”提出一种增强LLM逻辑推理的方法</li></ul><p>评估数据集不同</p><ul><li>前者使用多样化的逻辑推理数据集</li></ul><p>方法不同</p><ul><li>前者只评估模型现有能力</li><li>后者提出了人类推理模块来增强模型</li></ul><h3 id="共同点："><a href="#共同点：" class="headerlink" title="共同点："></a>共同点：</h3><ul><li><p>都关注提高LLM的逻辑推理能力</p></li><li><p>都构建了特定的评估数据集</p></li><li><p>都从理性和一致性等方面分析模型输出</p></li><li><p>都validation了模型在逻辑推理任务上的局限性</p></li><li><p>都提出了未来增强模型逻辑推理的方向</p></li></ul><h2 id="HRM数据集和该论文数据集对比"><a href="#HRM数据集和该论文数据集对比" class="headerlink" title="HRM数据集和该论文数据集对比"></a>HRM数据集和该论文数据集对比</h2><h3 id="重新介绍HRM的数据集："><a href="#重新介绍HRM的数据集：" class="headerlink" title="重新介绍HRM的数据集："></a><strong>重新介绍HRM的数据集：</strong></h3><h3 id="推理任务模型"><a href="#推理任务模型" class="headerlink" title="推理任务模型"></a>推理任务模型</h3><p>这个模型使用的数据集来自Cummins等人的研究,包含16个因果关系句子,以及对应4种论证形式的样本,例如:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">句子:&quot;如果踩下刹车,汽车会减速。&quot;</span><br><span class="line"></span><br><span class="line">论证形式:</span><br><span class="line">Modus Ponens:&quot;踩下了刹车,因此汽车减速了。&quot;</span><br><span class="line">Modus Tollens:&quot;汽车没有减速,因此刹车没有被踩下。&quot;</span><br></pre></td></tr></table></figure><h3 id="空间关系任务模型"><a href="#空间关系任务模型" class="headerlink" title="空间关系任务模型"></a>空间关系任务模型</h3><p>这个模型使用的样本为判断两个物体间关系的空间推理题。例如:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">前提1:B 在 A 的右边</span><br><span class="line">前提2:C 在 B 的左边</span><br><span class="line">问题:D和E之间的关系是?</span><br></pre></td></tr></table></figure><h3 id="贝叶斯推理任务模型"><a href="#贝叶斯推理任务模型" class="headerlink" title="贝叶斯推理任务模型"></a>贝叶斯推理任务模型</h3><p>该模型使用”栓片”(blicket)实验中的样本。给出一些木块,判断哪些是”栓片”,具有让检测器激活的因果能力。例如:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">训练阶段:</span><br><span class="line">块A放在检测器上,检测器激活。</span><br><span class="line">块B放在检测器上,检测器未激活。</span><br><span class="line"></span><br><span class="line">测试阶段:</span><br><span class="line">块C放在检测器上,检测器激活。</span><br><span class="line">判断块C是否为&quot;栓片&quot;?</span><br></pre></td></tr></table></figure><h3 id="对比HRM论文和LLM论文使用的数据集-我的理解是"><a href="#对比HRM论文和LLM论文使用的数据集-我的理解是" class="headerlink" title="对比HRM论文和LLM论文使用的数据集,我的理解是:"></a>对比HRM论文和LLM论文使用的数据集,我的理解是:</h3><ul><li>数据集规模不同</li></ul><p>HRM论文的模型验证数据集规模相对更小。例如第一个模型只使用了16个样本。</p><p>LLM论文使用了更大规模的公开逻辑推理数据集,一共15个,每个大约数百个样本。</p><ul><li>数据集构建不同</li></ul><p>HRM论文中的样本来源于相关的心理学实验研究。</p><p>LLM论文使用的大部分是已发表的数据集。</p><ul><li>数据集范围不同</li></ul><p>HRM论文使用的样本类型窄一些,每篇只关注一类推理。</p><p>LLM论文数据集涵盖演绎、归纳和假说等多类型推理。</p><ul><li>覆盖不同维度</li></ul><p>HRM论文数据集更侧重推理过程。</p><p>LLM论文数据集侧重结果的正确性。</p><ul><li>评估目标不同</li></ul><p>HRM论文数据集用于评估认知过程建模的符合度。</p><p>LLM论文数据集用于直接评估模型推理能力。</p><p>总体来说,HRM论文中使用的数据集更小规模、窄范围,但提供了丰富的过程信息,适合评估认知模型。LLM论文数据集则更大规模、综合,侧重结果评估,适合直接判断模型能力。两者服务于不同的研究目的。</p>]]></content>
      
      
      <categories>
          
          <category> Papers </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Papers </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Paper notes about Human Reasoning Module</title>
      <link href="/2023/07/01/Paper%20notes%20about%20HRM/"/>
      <url>/2023/07/01/Paper%20notes%20about%20HRM/</url>
      
        <content type="html"><![CDATA[<h1 id="Paper-Human-Reasoning-Module"><a href="#Paper-Human-Reasoning-Module" class="headerlink" title="Paper: Human Reasoning Module"></a>Paper: Human Reasoning Module</h1><p>link:<a href="https://citeseerx.ist.psu.edu/viewdoc/download;jsessionid=32CFA430A83B3069A4239DEB74F04FAB?doi=10.1.1.714.1165&rep=rep1&type=pdf">human reasoning module</a></p><p>Authors’Info:<br>Enkhbold Nyamsuren (<a href="mailto:&#x65;&#46;&#110;&#x79;&#x61;&#x6d;&#115;&#117;&#114;&#101;&#110;&#x40;&#114;&#x75;&#x67;&#46;&#x6e;&#108;">&#x65;&#46;&#110;&#x79;&#x61;&#x6d;&#115;&#117;&#114;&#101;&#110;&#x40;&#114;&#x75;&#x67;&#46;&#x6e;&#108;</a>) Department of Artificial Intelligence, University of Groningen, Nijenborgh 9, 9747 AG Groningen, Netherlands<br>Niels A. Taatgen (<a href="mailto:&#x6e;&#46;&#x61;&#x2e;&#116;&#97;&#97;&#116;&#103;&#x65;&#x6e;&#x40;&#x72;&#117;&#103;&#x2e;&#110;&#x6c;">&#x6e;&#46;&#x61;&#x2e;&#116;&#97;&#97;&#116;&#103;&#x65;&#x6e;&#x40;&#x72;&#117;&#103;&#x2e;&#110;&#x6c;</a>) Department of Artificial Intelligence, University of Groningen, Nijenborgh 9, 9747 AG Groningen, Netherlands</p><h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>这篇文章介绍了一种叫“Human Reasoning Module (HRM)”的框架，这是基于ACT-R实现的，ACT-R是一种人类认知结构的理论，这种认知模型可以预测诸如“学生思考算数问题的过程中，神经影像会展现出哪些活跃的部分”，详情可以参考此视频 <a href="https://youtu.be/5_RqQ56MxPE">Adaptive Control of Thought – Rational ACT- R By: John R. Anderson</a>，而HRM可以简单理解为是ACT-R理论的computer simulation，同时也是对ACT-R理论的一个extension及工具实现 具体的几个模型如何工作和实现的再往下看.</p><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>HRM的程序性知识结构定义了人类逻辑的语法，公理模式和推理规则等，HRM是基于知识块的，并且主张通过previous experience和real-time info推理并解决问题. 接下来就是HRM试图去解决的关于human reasoning的几个方面：</p><ul><li><p><strong>Inductive and deductive reasoning</strong></p><p>  作者觉得人的推论应该是probabilistic的，也就是不能是确定性的fact，没有被世界证明正确的未必是不正确的，保持开放然后去追求truthfulness而不是该推论的falstiy</p></li><li><p><strong>Mental logic, mental models and bottom-up reasoning</strong></p><p>  作者认为人类推理综合来看并不一定是自上而下的意识性的正式思考，心智逻辑和心智模型的理论百家争鸣，作者不排除这些理论的兼容性，也就是都为其所用，然后这个visual short-term memory (VSTM)就是自下而上的一种推理形式，可以说是动用了底层的人脑注意力，并不是一种归纳推理和其他推理形式。</p></li><li><p><strong>Deterministic and probabilistic inferences</strong></p></li></ul><p>HRM引入了一种简单有效的reasoning pipeline方式解决一些可能存在的冲突，基于视觉短时记忆推理的优先级比基于陈述性知识更高.</p><h2 id="Architecture-of-the-HRM"><a href="#Architecture-of-the-HRM" class="headerlink" title="Architecture of the HRM"></a>Architecture of the HRM</h2><ul><li><p><strong>Knowledge representation in declarative memory</strong><br>主要介绍了一下元组的表现形式和一些概念的定义设计</p></li><li><p><strong>Schema and inference types</strong><br>这个部分介绍了一下HRM采用了条件推理模式，同时设计了一些推理的规则，比如下方给出条件，假设成立，再看deduction是否make sense.<br>![Human Reasoning Module1](Human Reasoning Module1.jpg)</p></li><li><p><strong>Backward reasoning pipeline</strong><br>推理的pipleline如下，也就是说采用的手段优先级从高到低排列为：自下而上推理&gt;声明性检索&gt;自上而下推理<br><img src="/HRM2.jpg" alt="HRM2"></p></li><li><p><strong>Forward reasoning pipeline</strong></p></li></ul><p>这里是讲HRM如何基于用户提供的query去检索相关规则并推理，这里的前向推理管道是基于用户提供的查询语句，从声明性内存中检索与查询语句匹配的前提规则，并根据多个标准选择规则。然后HRM使用这些规则进行推理，从而生成结论或推断.<br><img src="/HRM3.jpg" alt="HRM3"></p><h2 id="Validation-Models"><a href="#Validation-Models" class="headerlink" title="Validation Models"></a>Validation Models</h2><p>Validation Models部分介绍了三个不同的实验任务模型，每个模型都用于复制人类行为，并根据人类表现数据进行验证。这些模型的目的是验证HRM的推理能力和有效性。</p><p>第一个模型是一个简单的推理任务模型，用于演示HRM基于声明性内存中的推理规则的基本推理能力。该模型仅使用声明性知识，不需要其他模块，如视觉。该模型使用的推理策略仅限于声明性规则的检索。该模型演示了即使在简单的推理任务中，竞争和冲突的声明性知识也会影响结果的重要性。它显示了在任何逻辑推理任务中考虑声明性检索结果的不确定性的重要性。</p><p>第二个模型是一个分类任务模型，用于演示HRM如何使用前向和后向推理来解决分类问题。该模型使用了视觉模块和声明性模块，以模拟人类在分类任务中的行为。该模型演示了HRM如何使用前向和后向推理来解决分类问题，并且可以在不同的分类任务中进行扩展。</p><p>第三个模型是一个因果推理任务模型，用于演示HRM如何使用因果推理来解决因果关系问题。该模型演示了HRM如何使用因果推理来解决因果关系问题，并且可以在不同的因果推理任务中进行扩展。</p><ul><li><p><strong>Model of Casual Deduction Task</strong><br>这里假设我们提供一个描述因果关系的句子，例如”If <cause>, then <effect>“。然后HRM会从声明性内存中检索与这个句子匹配的前提规则，并根据多个标准选择规则。接下来HRM使用这些规则进行推理，来生成结论或推断。<br>这里就是第一个模型的工作流程，可以看出来是在四种逻辑形式Modus Ponens (MP)，Modus Tollens (MT)，Affirmation of the Consequent (AC)，和Denial of the Antecedent (DA)里做选择然后检索相应的规则。<br><img src="/HRM4.jpg" alt="HRM4"></effect></cause></p></li><li><p><strong>Model of Spatial Relations Task</strong></p></li></ul><p>简单概括一下这个部分模型处理的过程：</p><ol><li><p>前提处理：模型首先接收四个前提，这些前提描述了物体之间的关系。模型使用这些前提来构建心理状态或形象，以表示前提中的物体。</p></li><li><p>心理状态构建：模型通过迭代地处理每个前提，逐步构建心理状态。在处理每个前提时，模型使用抽象对象来表示物体，并根据前提中的信息更新心理状态。</p></li><li><p>空间关系推导：通过构建好的心理状态，模型可以直接推导出两个查询物体之间的空间关系。模型利用心理状态中的信息来确定物体之间的关系，从而回答查询问题。</p></li></ol><ul><li><strong>Model of Bayesian-like Inference in Blicket Task</strong></li></ul><p>模型的推理策略：模型使用前向推理和后向推理相结合的方式进行推理。在前向推理中，模型根据观察到的方块放置情况和先前的知识进行推断。在后向推理中，模型根据观察到的结果和先前的知识来推断方块的属性。前向推理的步骤：模型首先根据观察到的方块放置情况进行前向推理。</p><h2 id="Discussion-and-Conclusion"><a href="#Discussion-and-Conclusion" class="headerlink" title="Discussion and Conclusion"></a>Discussion and Conclusion</h2><p>模型的良好拟合结果挑战了人类推理中确定性和概率推理之间的传统垂直分割观点。鉴于人类记忆的不一致性和召回的不确定性，确定性推理可以变得具有概率性。这种模型的拟合结果对于我们理解人类推理过程中的底层认知过程提供了详细的解释。HRM展示了人类思维展示的不同推理面向的单一系统。作为认知架构的一部分，HRM有望成为探索人类思维深处和生物启发的有用的工具。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Papers </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Papers </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Build QA system by using Google Bard API</title>
      <link href="/2023/06/30/Build%20QA%20system%20by%20using%20Google%20Bard%20API/"/>
      <url>/2023/06/30/Build%20QA%20system%20by%20using%20Google%20Bard%20API/</url>
      
        <content type="html"><![CDATA[<h3 id="Questions-for-me-you-can-ignore-this"><a href="#Questions-for-me-you-can-ignore-this" class="headerlink" title="Questions for me, you can ignore this."></a>Questions for me, you can ignore this.</h3><p>1.本质上这些还是问答的模型 那么我的数据集要构建成什么样子才能更有效呢 比如说我直接给它一篇文章 模型不知道要干什么 但是我随便给个prompt也不行 这里有待思考<br>2. 对于这些人为完成的新闻文本，很大概率存在一些歧义用词或者说特殊的网络用语，这些词需要去过滤吗 怎么去过滤<br>3. 模型自动调整参数使用gridSearch</p><h3 id="Issues-when-running-the-bard-chat"><a href="#Issues-when-running-the-bard-chat" class="headerlink" title="Issues when running the bard chat"></a>Issues when running the bard chat</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">from bardapi import ChatBard</span><br><span class="line">  </span><br><span class="line">chat = ChatBard(token=token,timeout=30, language=&#x27;en&#x27;)</span><br><span class="line">chat.start()</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>Error msg:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">---------------------------------------------------------------------------</span><br><span class="line">KeyError                                  Traceback (most recent call last)</span><br><span class="line">/var/folders/y8/lsp6my6s0699tykr6ghm_my80000gn/T/ipykernel_51118/1340303370.py in </span><br><span class="line">      2 </span><br><span class="line">      3 chat = ChatBard(token=token,timeout=30, language=&#x27;en&#x27;)</span><br><span class="line">----&gt; 4 chat.start()</span><br><span class="line"></span><br><span class="line">/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/bardapi/chat.py in start(self)</span><br><span class="line">     95             response = self.bard.get_answer(user_input)</span><br><span class="line">     96 </span><br><span class="line">---&gt; 97         if response.get(&quot;images&quot;):</span><br><span class="line">     98              print(f&quot;&#123;Fore.BLUE&#125;&#123;Style.BRIGHT&#125;Chatbot: &#123;response[&#x27;content&#x27;]&#125; \n\n Image links: &#123;response[&#x27;images&#x27;]&#125;&#123;Fore.RESET&#125;&#123;Style.RESET_ALL&#125;&quot;)</span><br><span class="line">     99         else:</span><br><span class="line"></span><br><span class="line">KeyError: &#x27;images&#x27;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>I was trying to modify the code in the python module ‘bardapi’ chat.py, you can find where is your module by run this:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">import bardapi</span><br><span class="line">print(bardapi.__file__)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>but it doesn’t work since the module seems always stay at the original version. Then even if I tried the code below, the error still remains.</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">import importlib</span><br><span class="line">import bardapi</span><br><span class="line"># Make changes to my_module.py</span><br><span class="line"></span><br><span class="line"># Reload the module</span><br><span class="line">importlib.reload(bardapi)</span><br></pre></td></tr></table></figure><p>Then I requested an issue on github. It has been fixed in the updated version.<br><img src="/issue1.png" alt="the github issue img"></p>]]></content>
      
      
      <categories>
          
          <category> C++ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> C++ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Notes on the book &lt;CODE COMPLETE&gt;</title>
      <link href="/2023/06/24/code%20complete%20Reading/"/>
      <url>/2023/06/24/code%20complete%20Reading/</url>
      
        <content type="html"><![CDATA[<h2 id="Chatper-1"><a href="#Chatper-1" class="headerlink" title="Chatper 1"></a>Chatper 1</h2><p>Software creating includes requirements analysis, architecturaldesign and detailed design, etc.</p><p>It’s significant to know </p>]]></content>
      
      
      <categories>
          
          <category> Reading notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Reading notes </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>code tricks/senses/basics</title>
      <link href="/2023/06/24/code%E6%8A%80%E5%B7%A7%E6%88%96%E5%B7%A5%E5%85%B7%E7%9B%B8%E5%85%B3%E5%B8%B8%E8%AF%86/"/>
      <url>/2023/06/24/code%E6%8A%80%E5%B7%A7%E6%88%96%E5%B7%A5%E5%85%B7%E7%9B%B8%E5%85%B3%E5%B8%B8%E8%AF%86/</url>
      
        <content type="html"><![CDATA[<h1 id="Everything-I-think-valuable-for-us"><a href="#Everything-I-think-valuable-for-us" class="headerlink" title="Everything I think valuable for us"></a>Everything I think valuable for us</h1><h3 id="Definiton-clarification-what’s-the-difference-between-the-“Dependencies”-and-the-“Requirements”？"><a href="#Definiton-clarification-what’s-the-difference-between-the-“Dependencies”-and-the-“Requirements”？" class="headerlink" title="Definiton clarification :what’s the difference between the “Dependencies” and the “Requirements”？"></a>Definiton clarification :what’s the difference between the “Dependencies” and the “Requirements”？</h3><p>“Dependencies” refer to external libraries or packages that your code relies on in order to function properly. “Requirements” typically refer to a specification of the minimum version of those dependencies that are necessary to run your code. In other words, “Requirements” tell the user what version of the “Dependencies” are needed for the code to work correctly.</p><h3 id="Why-use-Random-Seed-in-Machine-Learning"><a href="#Why-use-Random-Seed-in-Machine-Learning" class="headerlink" title="Why use Random Seed in Machine Learning?"></a>Why use Random Seed in Machine Learning?</h3><p>We use random seed value while creating training and test data set. The goal is to make sure we get the same training and validation data set while we use different hyperparameters or machine learning algorithms in order to assess the performance of different models. </p><h3 id="Recommended-pre-reading-materials"><a href="#Recommended-pre-reading-materials" class="headerlink" title="Recommended pre-reading materials"></a>Recommended pre-reading materials</h3><ul><li><p><a href="https://csdiy.wiki/">cs self-learning guide</a> <code>// every newbie should scan through it. // </code></p></li><li><p><a href="https://youtu.be/3tIqpEmWMLI">c++ tutorial from the cherno on youtube</a> ：<code>// it&#39;s a great tutorial for beginners //  </code></p></li><li><p><a href="https://parathan.medium.com/the-difference-between-module-package-and-library-in-python-e876f79ab2d8">The difference between Module, Package and Library in Python</a></p></li><li><p><a href="https://sspai.com/post/52980">colab basics</a> <code>// how to use colab to &quot;python&quot; //</code></p></li><li><p><a href="https://www.youtube.com/watch?v=tL1zltXuHO8">Quick Language Models using</a>  <code> // quick start using models //</code></p></li><li><p><a href="https://www.youtube.com/watch?v=-uleG_Vecis">100+ Computer Science Concepts Explained</a> <code>// basic terms concepts //</code></p></li><li><p><a href="https://www.youtube.com/watch?v=443UNeGrFoM">How I program C</a>：  <code>// basics and principles for writing c // last time watched till 1:37:05 / 2:11:31</code></p></li><li><p><a href="https://www.youtube.com/watch?v=hZS96dwKvt0">How to be a git expert </a><code>// git basics and workflow tutorial //</code></p></li><li><p><a href="https://github.com/youngyangyang04/leetcode-master">Awesome c++ leetcode solutions and program principels</a>   <code>// I was reading the part about programming style // </code></p></li><li><p><a href="https://stackoverflow.com/questions/15240815/git-fatal-the-remote-end-hung-up-unexpectedly%22">why git push fails and shows up”fatal: The remote end hung up unexpectedly”</a> And <a href="https://stackoverflow.com/questions/15240815/git-fatal-the-remote-end-hung-up-unexpectedly/64565533#64565533">more</a></p></li></ul><h3 id="how-to-better-debug-machine-learning-model"><a href="#how-to-better-debug-machine-learning-model" class="headerlink" title="how to better debug machine learning model"></a>how to better debug machine learning model</h3><ul><li><p>Learn how to debug machine learning model ： <a href="https://neptune.ai/blog/debugging-deep-learning-model-training">how to better debug machine learning model</a></p><p>  Recap： Since the machine learning model can “seems to be good”, but you have to test them if you ignore some detailed errors in the code. Just create tests that assert that the neural network architecture looks the way it is supposed to, checking the number of layers, the total number of trainable parameters, the value range of the output, and so on.</p></li><li><p>Using “from jsonargparse import CLI” to automatically pass arguments into parameters</p></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">Sure! Let<span class="string">&#x27;s say that you define the parameters look like this:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">** code **</span></span><br><span class="line"><span class="string">def prepare(</span></span><br><span class="line"><span class="string">    destination_path: Path = Path(&quot;data/alpaca&quot;), </span></span><br><span class="line"><span class="string">    tokenizer_path: Path = Path(&quot;checkpoints/lit-llama/tokenizer.model&quot;),</span></span><br><span class="line"><span class="string">    test_split_size: int = 2000,</span></span><br><span class="line"><span class="string">    max_seq_length: int = 256,</span></span><br><span class="line"><span class="string">    seed: int = 42,</span></span><br><span class="line"><span class="string">    mask_inputs: bool = False,  # as in alpaca-lora</span></span><br><span class="line"><span class="string">    data_file_name: str = DATA_FILE_NAME</span></span><br><span class="line"><span class="string">):..........</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">if __name__ == &quot;__main__&quot;:</span></span><br><span class="line"><span class="string">CLI(main)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">** code **</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Then you can use the command line like this ：</span></span><br><span class="line"><span class="string">python prepare_alpaca.py prepare --destination_path data/alpaca --tokenizer_path checkpoints/lit-llama/tokenizer.model --test_split_size 2000 --max_seq_length 256 --seed 42 --mask_inputs False --data_file_name alpaca_data_cleaned_archive.json</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">That means you can make &quot;passing the arguments into the parameters&quot; extremely flexible.</span></span><br><span class="line"><span class="string"></span></span><br></pre></td></tr></table></figure><ul><li>Use Ctrl + - (macOS) keyboard shortcut to navigate back to the last edited location in VScode.</li><li><a href="https://deepai.org/machine-learning-glossary-and-terms/softmax-layer">softmax - you have to know how does it work</a></li><li><a href="https://blog.finxter.com/chatgpt-api-temperature/">what is the “temperature” of LLM and how to tweak it</a></li><li><code>file=sys.stderr</code> is to separate error messages from regular output and redirect them to a separate file or stream for debugging purposes.</li></ul><p>E.g.<br><code>print(f&quot;Memory used: &#123;torch.cuda.max_memory_reserved() / 1e9:.02f&#125; GB&quot;, file=sys.stderr)</code></p><ul><li><a href="https://neptune.ai/blog/ml-model-debugging-and-tools">how to make sure your data is proper</a> &#x2F;&#x2F; <a href="https://neptune.ai/blog/data-preprocessing-guide">A Comprehensive Guide to Data Preprocessing</a><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">e</span><br></pre></td></tr></table></figure></li></ul>]]></content>
      
      
      <categories>
          
          <category> something you should know </category>
          
      </categories>
      
      
        <tags>
            
            <tag> something you should know </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2023/06/16/markdown%E8%AF%AD%E6%B3%95demo%20%E5%BF%98%E4%BA%86%E5%B0%B1%E7%9C%8B%E7%9C%8B/"/>
      <url>/2023/06/16/markdown%E8%AF%AD%E6%B3%95demo%20%E5%BF%98%E4%BA%86%E5%B0%B1%E7%9C%8B%E7%9C%8B/</url>
      
        <content type="html"><![CDATA[<p><a href="https://markdown-it.github.io/">markdown demo from github</a></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>lit-llama c++ on Mac M1</title>
      <link href="/2023/06/09/lit-llam%20c++%E7%89%88%E6%9C%AC/"/>
      <url>/2023/06/09/lit-llam%20c++%E7%89%88%E6%9C%AC/</url>
      
        <content type="html"><![CDATA[<p><a href="https://dev.l1x.be/posts/2023/03/12/using-llama-with-m1-mac/">https://dev.l1x.be/posts/2023/03/12/using-llama-with-m1-mac/</a></p><p><a href="https://github.com/ggerganov/llama.cpp">https://github.com/ggerganov/llama.cpp</a></p><p><a href="https://gist.github.com/cedrickchee/e8d4cb0c4b1df6cc47ce8b18457ebde0">https://gist.github.com/cedrickchee/e8d4cb0c4b1df6cc47ce8b18457ebde0</a></p><p><a href="https://matt-rickard.com/local-llama-m1-mac">https://matt-rickard.com/local-llama-m1-mac</a></p>]]></content>
      
      
      <categories>
          
          <category> LLM </category>
          
      </categories>
      
      
        <tags>
            
            <tag> LLM </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>lit-llama learning step by step(it tormented me but now you can relax due to this article)</title>
      <link href="/2023/06/08/lit-llama%E5%AD%A6%E4%B9%A0/"/>
      <url>/2023/06/08/lit-llama%E5%AD%A6%E4%B9%A0/</url>
      
        <content type="html"><![CDATA[<h2 id="read-first-to-know-the-rough-stuff"><a href="#read-first-to-know-the-rough-stuff" class="headerlink" title="read first to know the rough stuff"></a>read first to know the rough stuff</h2><p>Start from this article: <a href="https://lightning.ai/pages/community/tutorial/accelerating-llama-with-fabric-a-comprehensive-guide-to-training-and-fine-tuning-llama/">https://lightning.ai/pages/community/tutorial/accelerating-llama-with-fabric-a-comprehensive-guide-to-training-and-fine-tuning-llama/</a></p><p>Repo that mentioned in the article : <a href="https://github.com/Lightning-AI/lit-llama/blob/main/scripts/prepare_alpaca.py">https://github.com/Lightning-AI/lit-llama/blob/main/scripts/prepare_alpaca.py</a></p><p>downlaod the model weights and parameters ：<a href="https://github.com/Lightning-AI/lit-llama/blob/main/howto/download_weights.md">https://github.com/Lightning-AI/lit-llama/blob/main/howto/download_weights.md</a>    <a href="https://huggingface.co/nyanko7/LLaMA-7B/tree/main">https://huggingface.co/nyanko7/LLaMA-7B/tree/main</a></p><p>Bind your server repo to the github repo: <a href="https://levelup.gitconnected.com/fix-password-authentication-github-3395e579ce74">https://levelup.gitconnected.com/fix-password-authentication-github-3395e579ce74</a></p><h2 id="project-retrospective"><a href="#project-retrospective" class="headerlink" title="project retrospective"></a>project retrospective</h2><h3 id="Trick-to-upload-the-big-dataset"><a href="#Trick-to-upload-the-big-dataset" class="headerlink" title="Trick to upload the big dataset"></a>Trick to upload the big dataset</h3><p>Add the chrome extension “CurlWget”, and upload your data into OneDrive from microsoft（at least I tried it）and open the OneDrive on the webpage, choose your data in the web OneDrive and click the download button, then the extension I mentioned will capture the curl&#x2F;wget information, now you can cancel the download process since it doesn’t matter anymore. Afterwards, copy the whole information from the extension to your server&#x2F;local terminal, paste it, and execute it. Everything’s done, you will be over the moon when you see the upload speed up to 20Mb&#x2F;s（depends on your network）.</p><h3 id="autodl-A-server-rent-platform-data-disk-x2F-system-disk"><a href="#autodl-A-server-rent-platform-data-disk-x2F-system-disk" class="headerlink" title="autodl (A server rent platform) data disk&#x2F; system disk"></a>autodl (A server rent platform) data disk&#x2F; system disk</h3><p>when you try to upload the data just let it goes to the data disk since the storage of it can hold it, at least 50G</p><p>In addition, I would say open a terminal page to do the “cd” stuff will save your time af.</p><h3 id="Requirements-cking-important"><a href="#Requirements-cking-important" class="headerlink" title="Requirements(**cking important)"></a>Requirements(**cking important)</h3><p>lit-llama is compatible with pytroch&gt;&#x3D;2.0.0 IF NOT, the traceback will tell you the lack of torch.util.device module(roughly like this name, but may have some _ or - between them)</p><p>This one is good enough for me ：<a href="https://zhuanlan.zhihu.com/p/634963293">https://zhuanlan.zhihu.com/p/634963293</a> </p><p>My version here：</p><p>print(torch.<strong>version</strong>)2.0.0+cu117<br>print(torch.version.cuda)11.7<br>print(torch.cuda.is_available())True</p><h3 id="error-pytorchstreamreader-failed-reading-zip-archive-failed-finding-central-directory"><a href="#error-pytorchstreamreader-failed-reading-zip-archive-failed-finding-central-directory" class="headerlink" title="error: pytorchstreamreader failed reading zip archive: failed finding central directory"></a>error: pytorchstreamreader failed reading zip archive: failed finding central directory</h3><p>It’s annoying, but just make sure the file is downloaded completely and then everything will be okay. If you already download that just use the “ll -lh” to check the file size whether it equals to the original one. If not, just delete it and reupload it. </p><h3 id="Run-Test"><a href="#Run-Test" class="headerlink" title="Run Test"></a>Run Test</h3><p>Cd root&#x2F;lit-llama&#x2F;    </p><p>then  run : </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">!python generate.py --prompt <span class="string">&quot;Hello, my name is&quot;</span></span><br></pre></td></tr></table></figure><p>it will returns:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Loading model ..</span><br><span class="line">Time to load model: <span class="number">23.55</span> seconds.</span><br><span class="line">Global seed <span class="built_in">set</span> to <span class="number">1234</span></span><br><span class="line">Tell me the latest news about web3 <span class="keyword">and</span> ReadON app?</span><br><span class="line">The ReadON application has been updated <span class="keyword">and</span> <span class="keyword">is</span> now compatible <span class="keyword">with</span> version <span class="number">1.0</span><span class="number">.5</span><span class="number">.2285</span> of Web.</span><br><span class="line">This application <span class="keyword">is</span> an easy to use, high-quality, <span class="keyword">and</span> free tool that allows you to</span><br><span class="line">Time <span class="keyword">for</span> inference <span class="number">1</span>: <span class="number">2.06</span> sec total  <span class="number">24.22</span> tokens/sec</span><br><span class="line">Memory used :<span class="number">13.54</span>GB</span><br></pre></td></tr></table></figure><p>IF everything works, the terminal returns things like these, it demonstrates your requirements have been downloaded correctly.</p><h2 id="Tune-on-your-dataset"><a href="#Tune-on-your-dataset" class="headerlink" title="Tune on your dataset"></a>Tune on your dataset</h2><p>With only a few modifications, you can prepare and train on your own instruction dataset.</p><ol><li>Create a json file in which each row holds one instruction-response pair. A row has an entry for ‘instruction’, ‘input’, and ‘output’, where ‘input’ is optional an can be the empty string if the instruction doesn’t require a context. Below is an example json file:</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[</span><br><span class="line">    &#123;</span><br><span class="line">        &quot;instruction&quot;: &quot;Arrange the given numbers in ascending order.&quot;,</span><br><span class="line">        &quot;input&quot;: &quot;2, 4, 0, 8, 3&quot;,</span><br><span class="line">        &quot;output&quot;: &quot;0, 2, 3, 4, 8&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    ...</span><br><span class="line">]</span><br></pre></td></tr></table></figure><p>   ​</p><ol start="2"><li><p>Make a copy of <code>scripts/prepare_alpaca.py</code> and name it what you want:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cp scripts/prepare_alpaca.py scripts/prepare_mydata.py</span><br></pre></td></tr></table></figure><p>​</p></li><li><p>Modify <code>scripts/prepare_mydata.py</code> to read the json data file.</p></li><li><p>Run the script to generate the preprocessed, tokenized train-val split:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python scripts/prepare_mydata.py --destination_path data/mydata/</span><br></pre></td></tr></table></figure><p>​</p></li><li><p>Run <code>finetune/lora.py</code> by passing in the location of your data (and optionally other parameters):</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python finetune/lora.py --data_dir data/mydata/ --out_dir out/myexperiment</span><br></pre></td></tr></table></figure></li></ol><h2 id="Improve-the-performance"><a href="#Improve-the-performance" class="headerlink" title="Improve the performance"></a>Improve the performance</h2><p>To test the fine-tuned model, using the code below:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">python generate/adapter.py \</span><br><span class="line">    --prompt &quot;Recommend a movie to watch on the weekend.&quot; </span><br></pre></td></tr></table></figure><p>And the result totally sucks.</p><p>So “improve the dataset” hit my mind first. FYI, you can use your fliter methods to process your dataset.</p><h3 id="1-delete-the-image-description"><a href="#1-delete-the-image-description" class="headerlink" title="1.delete the image description"></a>1.delete the image description</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">lines = your_content.split(&quot;\n&quot;)</span><br><span class="line">filtered_lines = [line for line in lines if &quot;![img](&quot; not in line]</span><br></pre></td></tr></table></figure><h3 id="2-delete-the-unrelated-URL-x2F-emojis-x2F-…"><a href="#2-delete-the-unrelated-URL-x2F-emojis-x2F-…" class="headerlink" title="2.delete the unrelated URL&#x2F;emojis&#x2F;…."></a>2.delete the unrelated URL&#x2F;emojis&#x2F;….</h3><p><strong>re</strong> is a module which can use regular expression pattern to match and remove what you want.</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">import re</span><br><span class="line"></span><br><span class="line"># Open the input file</span><br><span class="line">with open(&#x27;your_data_path&#x27;, &#x27;r&#x27;) as f:</span><br><span class="line">    text = f.read()</span><br><span class="line"></span><br><span class="line"># Define the regular expression pattern to match emojis, URLs, &quot;&gt;_&quot;, &quot;&lt;3&quot;</span><br><span class="line">pattern = re.compile(u&#x27;[\U0001F600-\U0001F64F\U0001F300-\U0001F5FF&#x27;</span><br><span class="line">                     u&#x27;\U0001F680-\U0001F6FF\U0001F1E0-\U0001F1FF]&#x27;</span><br><span class="line">                     u&#x27;|[hH]ttps?\\S+|&gt;_+|&lt;3&#x27;)</span><br><span class="line"></span><br><span class="line"># Remove all text that matches the pattern</span><br><span class="line">filtered_text = pattern.sub(&#x27;&#x27;, text)</span><br><span class="line"></span><br><span class="line"># Write the filtered text to an output file</span><br><span class="line">with open(&#x27;your_output_path&#x27;, &#x27;w&#x27;) as f:</span><br><span class="line">    f.write(filtered_text)</span><br></pre></td></tr></table></figure><h3 id="3-dig-into-the-model-part"><a href="#3-dig-into-the-model-part" class="headerlink" title="3. dig into the model part"></a>3. dig into the model part</h3>]]></content>
      
      
      <categories>
          
          <category> LLM </category>
          
      </categories>
      
      
        <tags>
            
            <tag> LLM </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Information about internship assignments</title>
      <link href="/2023/06/04/%E5%AE%9E%E4%B9%A0%E4%BB%BB%E5%8A%A1LLM%E7%9B%B8%E5%85%B3%E8%B5%84%E6%BA%90%E5%92%8C%E6%80%9D%E8%80%83/"/>
      <url>/2023/06/04/%E5%AE%9E%E4%B9%A0%E4%BB%BB%E5%8A%A1LLM%E7%9B%B8%E5%85%B3%E8%B5%84%E6%BA%90%E5%92%8C%E6%80%9D%E8%80%83/</url>
      
        <content type="html"><![CDATA[<h2 id="LLaMA"><a href="#LLaMA" class="headerlink" title="LLaMA"></a>LLaMA</h2><p>Accelerating LLaMA with Fabric: A Comprehensive Guide to Training and Fine-Tuning LLaMA：<a href="https://lightning.ai/pages/community/tutorial/accelerating-llama-with-fabric-a-comprehensive-guide-to-training-and-fine-tuning-llama/">https://lightning.ai/pages/community/tutorial/accelerating-llama-with-fabric-a-comprehensive-guide-to-training-and-fine-tuning-llama/</a></p><p>LLaMA-Adapter: Efficient Fine-tuning of LLaMA 🚀：<a href="https://github.com/ZrrSkywalker/LLaMA-Adapter">https://github.com/ZrrSkywalker/LLaMA-Adapter</a></p><p>StackLLaMA: A hands-on guide to train LLaMA with RLHF：<a href="https://huggingface.co/blog/stackllama">https://huggingface.co/blog/stackllama</a></p><p>LLaMA github repo：<a href="https://github.com/facebookresearch/llama">https://github.com/facebookresearch/llama</a></p><h2 id="Alpaca"><a href="#Alpaca" class="headerlink" title="Alpaca"></a>Alpaca</h2><p>Stanford university’s Intro to Alpaca: A Strong, Replicable Instruction-Following Model：<a href="https://crfm.stanford.edu/2023/03/13/alpaca.html">https://crfm.stanford.edu/2023/03/13/alpaca.html</a></p><p>Alpaca-Lora:训练你自己的ChatGPT：<a href="https://zhuanlan.zhihu.com/p/615227156">https://zhuanlan.zhihu.com/p/615227156</a></p><p>Alpaca github repo：<a href="https://github.com/tatsu-lab/stanford_alpaca">https://github.com/tatsu-lab/stanford_alpaca</a></p>]]></content>
      
      
      <categories>
          
          <category> LLM </category>
          
      </categories>
      
      
        <tags>
            
            <tag> LLM </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Some remarks on Large Language Models</title>
      <link href="/2023/06/03/LLM%E7%9A%84%E7%BC%BA%E7%82%B9%E4%B8%8E%E5%8F%8D%E6%80%9D/"/>
      <url>/2023/06/03/LLM%E7%9A%84%E7%BC%BA%E7%82%B9%E4%B8%8E%E5%8F%8D%E6%80%9D/</url>
      
        <content type="html"><![CDATA[<h1 id="Some-remarks-on-Large-Language-Models"><a href="#Some-remarks-on-Large-Language-Models" class="headerlink" title="Some remarks on Large Language Models"></a>Some remarks on Large Language Models</h1><h4 id="Yoav-Goldberg-January-2023"><a href="#Yoav-Goldberg-January-2023" class="headerlink" title="Yoav Goldberg, January 2023"></a>Yoav Goldberg, January 2023</h4><p><strong>Audience:</strong> I assume you heard of chatGPT, maybe played with it a little, and was imressed by it (or tried very hard not to be). And that you also heard that it is “a large language model”. And maybe that it “solved natural language understanding”. Here is a short personal perspective of my thoughts of this (and similar) models, and where we stand with respect to language understanding.</p><h2 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h2><p>Around 2014-2017, right within the rise of neural-network based methods for NLP, I was giving a semi-academic-semi-popsci lecture, revolving around the story that <strong>achieving perfect language modeling is equivalent to being as intelligent as a human</strong>. Somewhere around the same time I was also asked in an academic panel “what would you do if you were given infinite compute and no need to worry about labour costs” to which I cockily responded <strong>“I would train a really huge language model, just to show that it doesn’t solve everything!”</strong>. Well, this response aged badly! or did it? And how does it co-exist with my perfect-language-modeling-as-intelligence story I was also telling at the same time?</p><h2 id="Perfect-Language-Modeling-is-AI-Complete"><a href="#Perfect-Language-Modeling-is-AI-Complete" class="headerlink" title="Perfect Language Modeling is AI-Complete"></a>Perfect Language Modeling is AI-Complete</h2><p>My pop-sci-meets-intro-NLP talk (“teaching computers to understand language”) was centered around Claude Shannon’s “guessing game” and the idea of language modeling. It started with AI-for-games, then quickly switched to “a different kind of game” invented by Shannon in 1951: the game of “guessing the next letter”. The game operator chooses some text and a cutting point within the text, and hides the end. The players need to guess the first hidden letter in the smallest number of gueses. </p><p>I gave a few examples of this game, that demonstrate various kinds of linguistic knowledge that are needed in order to perform well in it, at different levels of linguistic understanding (from morphology through various levels of syntax, smantics, pragmatics and sociolinguistics).<br>And then I said that humans are great at this game without even practicing, and that’s it is hard for them to get better at it, which is why they find it to be a not-great game. </p><p>I then said that computers kinda suck at this game compared to humans, but that by teaching them to play it, we gain a lot of implicit knowledge of language. And that there is a long way to go, but that there was some steady progress: this is how machine translation works today! </p><p>I also said that computers are still not very good, and that this is understandable: the game is “AI-complete”: really playing the game “at human level” would mean solving every other problem of AI, and exhibiting human-like intelligence. To see why this is true, consider that the game entails completing <em>any</em> text prefix, including very long ones, including dialogs, including every possible conversation prefix, including every description of experience that can be expressed in human language, including every answer to every question that can be asked on any topic or situation, including advanced mathmatics, including philosophy, and so on. In short, to play it well, you need to <em>understand</em> the text, understand the situation described in the text, <em>imagine</em> yourself in the situation, and then to <em>respond</em>. It really mimicks the human experience and thought. (Yes, there could be several objections to this argument, for example humans may also need to ask questions about images or scenes or other perceptual inputs that the model cannot see. But I think you get the point.)</p><p>So that was the the story I told about Shannon’s guessing game (aka “language modeling”) and how playing it at human level entails human level intelligence.</p><h2 id="Building-a-large-language-model-won’t-solve-everything-x2F-anything"><a href="#Building-a-large-language-model-won’t-solve-everything-x2F-anything" class="headerlink" title="Building a large language model won’t solve everything &#x2F; anything"></a>Building a large language model won’t solve everything &#x2F; anything</h2><p>Now, if obtaining the ability of perfect language modeling entails intelligence (“AI-complete”), why did I maintain that building the largest possible language model won’t “solve everything”? and was I wrong? </p><p>The answer is that I didn’t think building a very large language model based on the then-existing tech (which was then just shifting between RNNs&#x2F;LSTMs and the Transformer) will get us nowhere even close to having “perfect language modeling”.</p><p>Was I wrong? sort of. I was definitely surprised by the abilities demonstrated by large language models. There turned out to be a phase shift somewhere between 60B parameters and 175B parameters, that made language models super impressive. They do a lot more than what I thought a language model trained on text and based on RNNs&#x2F;LSTMs&#x2F;Transformers could ever do. They certainly do all the things I had in mind when I cockily said they will “not solve everything”. </p><p>Yes, current-day language models (first release of chatGPT) did “solve” all of the things in the set of language understanding problems I was implicitly considering back then. So in that sense, I was wrong. But in another sense, no, it did not solve <em>everything</em>. Not yet, at least. Also, the performance of current day language-models is not obtained only by language modeling in the sense I had in mind then. I think this is important, and I will elaborate on it a bit soon.</p><p>In what follows I will briefly discuss the difference I see between current-day-LMs and what was then perceived to be an LM, and then briefly go through some of the things I think are not yet “solved” by the large LMs. I will also mention some arguments that I find to be correct but irrelevant &#x2F; uninteresting.</p><h2 id="Natural-vs-Currated-Lanagueg-Modeling"><a href="#Natural-vs-Currated-Lanagueg-Modeling" class="headerlink" title="Natural vs Currated Lanagueg Modeling"></a>Natural vs Currated Lanagueg Modeling</h2><p>What do I mean by “The performance of current days language models are not obtained by language modeling”? The first demonstration of large language models (let’s say at the 170B parameters level, a-la GPT-3) was (to the best of our knowledge) trained on naturally occuring text data: text found in books, crawled from the internet, found in social networks, etc. Later replications (BLOOM, OPT) also used similar data. This is very close to Shannon’s game, and also what most people in the past few decades thought of as ‘language modeling’. These models already brought remarkable performance. But chatGPT is different.</p><p>What’s different in chatGPT? There are three conceptual steps between GPT-3 and chatGPT:<br>Instructions, code, RLHF. The last one is, I think, the least interesting despite getting the most attention, but all are interesting. Here’s my hand-wavy explanation. Maybe some day I will turn it into a more formal argument. I hope you get an intuition out of it though.</p><p>Training on “text alone” like a “traditional language model” does have some clear theoretical limitations. Most notably, it doesn’t have a connection to anything “external to the text”, and hence cannot have access to “meaning” or to “communicative intent”. Another way to say it is that the model is “not grounded”. The symbols the model operates on are just symbols, and while they can stand in relation to one another, they do not “ground” to any real-world item. So we can know the <em>symbol</em> “blue”, but there is no real-world concept behind it.</p><p>In <strong>instruction tuning</strong> the model trainers stopped training on just “found” data, and started trainign on also on specific human-created data (this is known in machine-learning circles as “supervised learning”, e.g. learning from annotated examples), in addition to the found one. For example, the human annotators would write something like “please summarize this text”, followed by some text they got, followed by a summary they produced of this text. Or, they may write “translate this text into a formal language”, followed by some text, followed by formal language. They would create many instructions of these kind (many summaries, many translations, etc), for many different “tasks”. And then these will be added to the model’s training data.<br><strong>Why is this significant?</strong> At the core the model is still doing language modeling, right? learning to predict the next word, based on text alone? Sure, but here the human annotators inject some level of grounding to the text. Some symbols (“summarize”, “translate”, “formal”) are used in a consistent way together with the concept&#x2F;task they denote. And they always appear in the beginning of the text. This make these symbols (or the “instructions”) in some loose sense external to the rest of the data, making the act of producing a summary grounded to the human concept of “summary”. Or in other words, this helps the model learn the <em>communicative intent</em> of the a user who asks for a “summary” in its “instruction”.<br><strong>An objection</strong> here would be that such cases likely naturally occur already in large text collections, and the model already learned from them, so what is new here? <strong>I argue</strong> that it might be much easier to learn from direct instructions like these than it is to learn from non-instruction data (think of a direct statement like “this is a dog” vs needing to infer from over-hearing people talk about dogs). And that by shifting the distribution of the training data towards these annotated cases, substantially alter how the model acts, and the amount of “grounding” it has. And that maybe with explicit instructions data, we can use much less training text compared to what was needed without them. (I promised you hand waving didn’t I?)</p><p>Additionally, the latest wave of models is also trained on <strong>programming language code</strong> data, and specifically data that contains both natural language instructions or descriptions (in the form of code comments) and the corresponding programming language code.<br><strong>Why is this significant?</strong> This produced another very direct form of <em>grounding</em>. Here, we have two separate systems in the stream of text: one of them is the human language, and the other is the programming language. And we obsere the direct interaction between these two systems: the human language describes concepts (or <em>intents</em>), which are then <em>realized</em> in the form of the corresponding programs. This is now a quite explicit “form to meaning pairing”. We can certainly learn more from it than what we could learn “from form alone”. (Also, I hypothesize that latest models are also trained on <em>execution</em>: pairs of programs and their outputs. This is an even stronger form of grounding: denotations). This is now very far from “just” language modeling.</p><p>Finally, <strong>RLHF, or “RL with Human Feedback”.</strong> This is a fancy way of saying that the model now observes two humans in a conversation, one playing the role of a user, and another playing the role of “the AI”, demonstrating how the AI should respond in different situations. This clearly helps the model learn how dialogs work, and how to keep track of information across dialog states (something that is very hard to learn from just “found” data). And the instructions to the humans are also the source of all the “It is not appropriate to…” and other formulaic &#x2F; templatic responses we observe from the model. It is a way to train to “behave nicely” by demonstration.</p><p>ChatGPT has all three of these, if not more. This is why I find it to be very different from “traditional” language models, why it may not “obey” some of the limitations we (or I) expect to from language models, and why it performs so much better on many tasks: it is a <em>supervised model</em>, with <em>access to an external modality</em>, which is also trained explicitly by demonstration to <em>follow a large set of instructions</em> given in dialog form.</p><h2 id="What’s-still-missing"><a href="#What’s-still-missing" class="headerlink" title="What’s still missing?"></a>What’s still missing?</h2><h3 id="Common-yet-boring-arguments"><a href="#Common-yet-boring-arguments" class="headerlink" title="Common-yet-boring arguments"></a>Common-yet-boring arguments</h3><p>There are a bunch of commonly occuring arguments about language models, which I find to be true but uninspiring &#x2F; irrelevant to my discussion here:</p><ul><li>They are <strong>wasetful</strong>, training them is very expensive, using them is very expensive. <ul><li>Yes, this is certainly true today. But things get cheaper over time. Also, let’s put things in perspective: yes, it is enviromentally costly, but we aren’t training that many of them, and the total cost is miniscule compared to all the other energy consumptions we humans do. And, I am also not sure what the environmental argument has to to with the questions of “are these things interesting”, “are these things useful”, etc. It’s an economic question.</li></ul></li><li>The models encode many <strong>biases</strong> and <strong>stereotypes</strong>. <ul><li>Well, sure they do. They model observed human’s language, and we humans are terrible beings, we are biased and are constantly stereotyping. This means we need to be careful when applying these models to real-world tasks, but it doesn’t make them less valid, useful or interesting from a scientiic perspective.</li></ul></li><li>The models <strong>don’t <em>really</em> understand</strong> language. <ul><li>Sure. They don’t. So what? Let’s focus on what they do manage to do, and maybe try to improve where they don’t?</li></ul></li><li>These models <strong>will never <em>really</em> understand language.</strong> <ul><li>Again, so what? There are parts they clearly cover very well. Let’s look at those? Or don’t look at them if you don’t care about these aspects. Those who want to <em>really</em> <em>understand</em> language may indeed prefer to look elsewhere. I am happy with approximate understanding.</li></ul></li><li>The models <strong>do not understand language like humans do</strong>. <ul><li>Duh? they are not humans? Of course they differ in some of their mechanisms. They still can tell us a lot about language structure. And for what they don’t tell us, we can look elsewhere.</li></ul></li><li>You <strong>cannot learn anything meaningful based only on form</strong>:<ul><li>But it is not trained only on form, see section above.</li></ul></li><li>It <strong>only connects pieces its seen before</strong> according to some statistics.<ul><li>…And isn’t it <strong>magnificent</strong> that “statistics” can get you so far? The large models connect things in a very powerful way. Also, consider how many <em>terribly wrong</em> ways there are to connect words and phrases from the corpus according to statistics. And how many such ways the models manage to avoid, and somehow choose “meaningful” ones. I find this utterly remarkable.</li></ul></li><li>We <strong>do not know the effects these things may have on society:</strong><ul><li>This is true about any new tech &#x2F; new discovery. Let’s find out. We can try and be careful about it. But that doesn’t make the thing less interesting &#x2F; less effective &#x2F; less worthy of study. It just adds one additional aspect worth studying.</li></ul></li><li><strong>The models don’t cite their sources:</strong> <ul><li>Indeed they don’t. But… so what? I can see why you would like that in certain kinds of applications, and you certainly want the models to not bulshit you, and maybe you want to be able to <em>verify</em> that they don’t bulshit you, but these are all not really related to the core of what language models are &#x2F; this is not the right question to ask, in my opinion. After all, humans don’t really “cite their sources” in the real sense, we rarely attribute our knowledge to a specific single source, and if we do, we very often do it as a rationalization, or in a very deliberate process of first finding a source and then citing it. This can be replicated. From an application perspective (say, if we want to develop a search system, or a paper writing system, or a general-purpose question answering system), people can certainly work on linking utterances to sources, either through the generation process or in a post-processing step, or on setups where you first retrieve and then generate. And many people do. But this is not really related to language understanding. What <strong>is</strong> interesting though, and what I find to be a more constructive thing to ask for, is (a) how do we separate “core” knowledge about language and reasoning, from specific factual knowledge about “things”; and (b) how do we enable knowledge of knowledge (see below).</li></ul></li></ul><h2 id="So-what’s-missing-x2F-what-are-some-real-limitations"><a href="#So-what’s-missing-x2F-what-are-some-real-limitations" class="headerlink" title="So what’s missing &#x2F; what are some real limitations?"></a>So what’s missing &#x2F; what are some real limitations?</h2><p>Here is an informal and incomplete list of things that I think are currently challenging in current “large language models”, including the latest chatGPT, and which hinders them from “fully understanding” language is some real sense. These are a bunch of things the models still cannot do, or are at least very ill-equipped to do.</p><ul><li><p><strong>Relating multiple texts to each other</strong>. In their training, the models consume text either as one large stream, or as independent pieces of information. They may pick up patterns of commonalities in the text, but it has no notion of how the texts relate to “events” in the real world. In particular, if the model is trained on multiple news stories about the same event, it has no way of knowing that these texts all describe the same thing, and it cannot differentiate it from several texts describing similar but unrelated events. In this sense, the models cannot really form (or are really not equipped to form) a coherent and complete world view from all the text they “read”. </p></li><li><p><strong>A notion of time</strong>. Similarly, the models don’t have a notion of which events <em>follow</em> other events in their training stream. They don’t really have a notion of time at all, besides maybe explicit mentions of time. So it may learn the local meaning of expressions like “Obama became president in 2009”, and “reason” about other explicitly dated things that happened before or after this. But it cannot understand the flow of time in the sense that if it reads (in a separate text) that “Obama is the current president of the united state” and yet in a third text that “Obame is no longer the president”, which of these things follow one another, and what is true <em>now</em>. It can concurrently “believe” that both “Obame is the current president of the US”, “Trump is the current president of the US” and “Biden is the current president of the US” are all valid statements. Similarly, it really has no practical way of interpreting statments like “X is the latest album by Y” and how they stand in relation to each other.</p></li><li><p><strong>Knowledge of Knowledge</strong> The models don’t really “know what they know”. They don’t even know what “knowing” is. All they do is guess the next token in a stream, and this next token guess may be based on either well founded acuired knowledge, or it may be a complete guess. The models’ training and training data have no explicit mechanism for distingushing these two cases, and certainly don’t have explicit mechanisms to act differently according to them. This is manifested in the well documented tendency to “confidently make stuff up”. The learning-from-demonstraiton (RLHF) made the models “aware” that some answers should be treated with caution, and maybe the models even learned to associate this level of caution with the extent to which some fact, entity or topic were covered in their training data, or the extent to which the data is reflected in their internal weights. So in that sense they exhibit <em>some</em> knowledge of knowledge. But when they get over this initial stage of refuding to answer, and go into “text generation mode”, they “lose” all such knowledge of knowledge, and, very quickly tranistion into “making stuff up” mode, also on things that it clearly stated (in a different stage) that is has no knowledge of.</p></li><li><p><strong>Numbers and math</strong> The models are really ill-equipped to perform math. Their basic building blocks are “word pieces”, which don’t really correspond to numbers in any convenient base. They also don’t have any appropriate way of learning the relations between different numebrs (such as the +1 or “greater than” relations) in any meaningful and consistent way. LLMs manage to perform semi-adequately on some questions involving numbers, but really there are <strong>so much better</strong> ways to go about representing numbers and math than the mechanisms we gave LLM, that it is surprising they can do anything at all. But I suspect they will not get very far without some more explicit modeling.</p></li><li><p><strong>Rare events, high recall setups, high coverage setups:</strong> By their nature, the models focus on the common and probable cases. This makes me immediately suspicious about their ability to learn from rare events in the data, or to recall rare occurances, or to recall all occurances. Here I am less certain than in the other points: they might be able to do it. But I am currently skeptical.</p></li><li><p><strong>Data hunger</strong> This is perhaps <strong>the biggest technical issue</strong> I see with current large language models: they are extremely data hungry. To achieve their impressive performance, they were trained on trillions of words. The obvious “<strong>…and humans learn from a tiny fraction of this</strong>“  is of course true, but not very interesting to me on its own: so what? we don’t have to mimick humans to be useful. There are other implications though, that I find to be very disturbing: <strong>Most human languages don’t have so much data</strong>, certainly not data vailable in digital form. </p><p><strong>Why is this significant?</strong> Because it means that we will be hard-pressed to replicate the incredible English understanding results that we have now for <strong>other languages</strong>, such as my native language Hebrew, or even to more common ones like German, French or Arabic, or even Chinese or Hindi (I don’t even consider so called “low resource” language like the many african and phillipinian ones). </p><p>We can get a lot of data in these language, but not <em>so much</em> data. Yes, with “instruct training” we may need less data. But then the instruction data needs to be created: this is a huge undertaking for each new language we want to add. Additionally, if we believe (and I do) that training on code + language is significant, this is another <strong>huge</strong> barrirer for achieving similar models for languages other than English.</p><p><strong>Can’t this be solved by translation?</strong> after all, we have great progress also in machine translation. We can translate to English, run the model there, and then translate back. Well, yes, we could. <strong>But this will work only at a very superficial level</strong>. Different languages come from different geographical regions, and these regions have their local cultures, norms, stories, events, and so on. These differ from the cultures, norms, stories and events of English speaking geographies in various ways. Even a simple concept such as “a city” differs across communities and geographies, not to mention concepts such as “politeness” or “violence”. Or “just” “factual” knowledge about certain people, historic events, significant places, plants, customs, etc. These will not be reflected in the English training data, and cannot be covered by translation.</p><p>So, data hunger <em>is</em> a real problem, if we consider that we may want to have language understanding and “AI” technologies also outside of English.</p><p>For those of us who want to worry about social implications, this combination of data-hunger and English&#x2F;US-centrality is definitely a huge issue to consider.</p></li><li><p><strong>Modularity</strong>  At the end of the “common yet boring arguments” section above, I asked “<strong>how do we separate “core” knowledge about language and reasoning, from specific factual knowledge about “things”</strong>“. I think this is a major question to ask, and that solving it will go a long way towards making progress (if not “solving”) many of the other issues. If we can modularize and separate the “core language understanding and reasoning” component from the “knowledge” component, we may be able to do much better w.r.t to the data-hunger problem and the resulting cultural knowledge gaps, we may be able to better deal with and control biases and stereotypes, we may get knowledge-of-knowledge almost “for free”. (Many people are working on “retrieval augmented language models”. This may or may not be the right way to approach this problem. I tend to suspect there is a more fundamental approach to be found. But history has proven I don’t have great intuitions about such things.)</p></li></ul><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>Large language models are amazing. Language modeling is not enough, but “current language models” are actually more than language models, and they can do much more than we expected.<br>This is still “not enough”, though, if we care about “inclusive” language understanding, and also if we don’t.  </p><p>Transship from Prof. Yoav Goldberg <a href="https://gist.github.com/yoavg/59d174608e92e845c8994ac2e234c8a9#file-llms-md">https://gist.github.com/yoavg/59d174608e92e845c8994ac2e234c8a9#file-llms-md</a></p>]]></content>
      
      
      <categories>
          
          <category> LLM </category>
          
      </categories>
      
      
        <tags>
            
            <tag> LLM </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>How to use Google Bard API</title>
      <link href="/2023/06/01/BARD_API/"/>
      <url>/2023/06/01/BARD_API/</url>
      
        <content type="html"><![CDATA[<h1 id="Google-Bard-API"><a href="#Google-Bard-API" class="headerlink" title="Google  Bard API"></a>Google <a href="https://bard.google.com/"><img src="https://camo.githubusercontent.com/adb54264fe2ad5067d07d0752fc32600b4e6250073b01ce8c386575b431e3f06/68747470733a2f2f7777772e677374617469632e636f6d2f6c616d64612f696d616765732f66617669636f6e5f76315f31353031363063646466663766323934636533302e737667" alt="img"></a> Bard API</h1><p><a href="https://github.com/dsdanielpark/Bard-API/blob/main/assets/bard_api.gif"><img src="https://github.com/dsdanielpark/Bard-API/raw/main/assets/bard_api.gif" alt="img"></a></p><p>If you will not provide the language parameter (use <code>english</code>, <code>korean</code>, <code>japanese</code> only as input text):</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pip install bardapi</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>If you wish to use the Bard API, including various features:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install git+https://github.com/dsdanielpark/Bard-API.git</span><br></pre></td></tr></table></figure><h2 id="Authentication"><a href="#Authentication" class="headerlink" title="Authentication"></a>Authentication</h2><blockquote><p>Warning Do not expose the <code>__Secure-1PSID</code></p></blockquote><ol><li>Visit <a href="https://bard.google.com/">https://bard.google.com/</a></li><li>F12 for console</li><li>Session: Application → Cookies → Copy the value of  <code>__Secure-1PSID</code> cookie.</li></ol><p>Note that while I referred to <code>__Secure-1PSID</code> value as an API key for convenience, it is not an officially provided API key. Cookie value subject to frequent changes. Verify the value again if an error occurs. Most errors occur when an invalid cookie value is entered.</p><p>If you need to set multiple Cookie values</p><ul><li><a href="https://github.com/dsdanielpark/Bard-API/blob/main/README_DEV.md#bard-which-can-get-cookies">Bard Cookies</a> - After confirming that multiple cookie values are required to receive responses reliably in certain countries, I will deploy it for testing purposes. Please debug and create a pull request</li></ul><h2 id="Usage"><a href="#Usage" class="headerlink" title="Usage"></a>Usage</h2><p><a href="https://colab.research.google.com/drive/1zzzlTIh0kt2MdjLzvXRby1rWbHzmog8t?usp=sharing"><img src="https://camo.githubusercontent.com/84f0493939e0c4de4e6dbe113251b4bfb5353e57134ffd9fcab6b8714514d4d1/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667" alt="Open In Colab"></a></p><p>Simple Usage</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">from bardapi import Bard</span><br><span class="line"></span><br><span class="line">token = &#x27;xxxxxxx&#x27;</span><br><span class="line">bard = Bard(token=token)</span><br><span class="line">bard.get_answer(&quot;나와 내 동년배들이 좋아하는 뉴진스에 대해서 알려줘&quot;)[&#x27;content&#x27;]</span><br></pre></td></tr></table></figure><p>Or you can use this</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">from bardapi import Bard</span><br><span class="line">import os</span><br><span class="line">os.environ[&#x27;_BARD_API_KEY&#x27;]=&quot;xxxxxxx&quot;</span><br><span class="line"></span><br><span class="line">Bard().get_answer(&quot;나와 내 동년배들이 좋아하는 뉴진스에 대해서 알려줘&quot;)[&#x27;content&#x27;]</span><br></pre></td></tr></table></figure><p>To get reponse dictionary</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">import bardapi</span><br><span class="line">import os</span><br><span class="line"></span><br><span class="line"># set your __Secure-1PSID value to key</span><br><span class="line">token = &#x27;xxxxxxx&#x27;</span><br><span class="line"></span><br><span class="line"># set your input text</span><br><span class="line">input_text = &quot;나와 내 동년배들이 좋아하는 뉴진스에 대해서 알려줘&quot;</span><br><span class="line"></span><br><span class="line"># Send an API request and get a response.</span><br><span class="line">response = bardapi.core.Bard(token).get_answer(input_text)</span><br></pre></td></tr></table></figure><p>Addressing errors caused by delayed responses in environments like Google Colab and containers. If an error occurs despite following the proper procedure, utilize the timeout argument.</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">from bardapi import Bard</span><br><span class="line">import os</span><br><span class="line">os.environ[&#x27;_BARD_API_KEY&#x27;]=&quot;xxxxxxx&quot;</span><br><span class="line"></span><br><span class="line">bard = Bard(timeout=30) # Set timeout in seconds</span><br><span class="line">bard.get_answer(&quot;나와 내 동년배들이 좋아하는 뉴진스에 대해서 알려줘&quot;)[&#x27;content&#x27;]</span><br></pre></td></tr></table></figure><h2 id="Further"><a href="#Further" class="headerlink" title="Further"></a>Further</h2><h3 id="Behind-a-proxy"><a href="#Behind-a-proxy" class="headerlink" title="Behind a proxy"></a>Behind a proxy</h3><p>If you are working behind a proxy, use the following.</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">from bardapi import Bard</span><br><span class="line">import os</span><br><span class="line"></span><br><span class="line"># Change &#x27;http://proxy.example.com:8080&#x27; to your http proxy</span><br><span class="line"># timeout in seconds</span><br><span class="line">proxies = &#123;</span><br><span class="line">    &#x27;http&#x27;: &#x27;http://proxy.example.com:8080&#x27;,</span><br><span class="line">    &#x27;https&#x27;: &#x27;https://proxy.example.com:8080&#x27;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">bard = Bard(token=&#x27;xxxxxxx&#x27;, proxies=proxies, timeout=30)</span><br><span class="line">bard.get_answer(&quot;나와 내 동년배들이 좋아하는 뉴진스에 대해서 알려줘&quot;)[&#x27;content&#x27;]</span><br></pre></td></tr></table></figure><h3 id="Reusable-session-object"><a href="#Reusable-session-object" class="headerlink" title="Reusable session object"></a>Reusable session object</h3><p>You can continue the conversation using a reusable session.</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">from bardapi import Bard</span><br><span class="line">import os</span><br><span class="line">import requests</span><br><span class="line">os.environ[&#x27;_BARD_API_KEY&#x27;] = &#x27;xxxxxxx&#x27;</span><br><span class="line"># token=&#x27;xxxxxxx&#x27;</span><br><span class="line"></span><br><span class="line">session = requests.Session()</span><br><span class="line">session.headers = &#123;</span><br><span class="line">            &quot;Host&quot;: &quot;bard.google.com&quot;,</span><br><span class="line">            &quot;X-Same-Domain&quot;: &quot;1&quot;,</span><br><span class="line">            &quot;User-Agent&quot;: &quot;Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.114 Safari/537.36&quot;,</span><br><span class="line">            &quot;Content-Type&quot;: &quot;application/x-www-form-urlencoded;charset=UTF-8&quot;,</span><br><span class="line">            &quot;Origin&quot;: &quot;https://bard.google.com&quot;,</span><br><span class="line">            &quot;Referer&quot;: &quot;https://bard.google.com/&quot;,</span><br><span class="line">        &#125;</span><br><span class="line">session.cookies.set(&quot;__Secure-1PSID&quot;, os.getenv(&quot;_BARD_API_KEY&quot;)) </span><br><span class="line"># session.cookies.set(&quot;__Secure-1PSID&quot;, token) </span><br><span class="line"></span><br><span class="line">bard = Bard(token=token, session=session, timeout=30)</span><br><span class="line">bard.get_answer(&quot;나와 내 동년배들이 좋아하는 뉴진스에 대해서 알려줘&quot;)[&#x27;content&#x27;]</span><br><span class="line"></span><br><span class="line"># Continued conversation without set new session</span><br><span class="line">bard.get_answer(&quot;What is my last prompt??&quot;)[&#x27;content&#x27;]</span><br></pre></td></tr></table></figure><p>Transship from <a href="https://github.com/dsdanielpark/Bard-API">https://github.com/dsdanielpark/Bard-API</a></p><p>Found it when viewing <a href="https://twitter.com/nevrekaraishwa2/">https://twitter.com/nevrekaraishwa2/</a></p>]]></content>
      
      
      <categories>
          
          <category> Tools </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Tools </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Simple thinking</title>
      <link href="/2023/05/28/%E4%BA%BA%E7%94%9F%E6%80%9D%E8%80%83/"/>
      <url>/2023/05/28/%E4%BA%BA%E7%94%9F%E6%80%9D%E8%80%83/</url>
      
        <content type="html"><![CDATA[<ul><li>In the beginning you always want the results. In the end all you want is control.</li></ul>]]></content>
      
      
      <categories>
          
          <category> something you should know </category>
          
      </categories>
      
      
        <tags>
            
            <tag> something you should know </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>What’s the Difference Between a Programmer, Coder, Developer, and Software Engineer?</title>
      <link href="/2023/05/28/%E5%A5%BD%E7%8E%A9%E7%9A%84%E4%B8%9C%E8%A5%BF/"/>
      <url>/2023/05/28/%E5%A5%BD%E7%8E%A9%E7%9A%84%E4%B8%9C%E8%A5%BF/</url>
      
        <content type="html"><![CDATA[<h2 id="What’s-the-Difference-Between-a-Programmer-Coder-Developer-and-Software-Engineer"><a href="#What’s-the-Difference-Between-a-Programmer-Coder-Developer-and-Software-Engineer" class="headerlink" title="What’s the Difference Between a Programmer, Coder, Developer, and Software Engineer?"></a>What’s the Difference Between a Programmer, Coder, Developer, and Software Engineer?</h2><p>Even for those who are working in the technology industry, these titles seem to be very confusing. So, how do you differentiate between these terms and know what do they all mean and who do you turn to when you just need to get something done?</p><p>In reality, these terms are often used interchangeably, that vary from organization to organization, and can even mean different things depending on the circumstance. Let’s have a look at each title below and see what it means.</p><p>Difference Between a Programmer, Coder, Developer, and Software Engineer.</p><h3 id="Coders"><a href="#Coders" class="headerlink" title="Coders"></a>Coders</h3><p>Anyone who can write some code is often referred to as a coder by the people outside of the tech industry. But, usually, coders are considered the least trained or experienced level of programmers. These individuals do not have the same algorithmic knowledge as a programmer or developer, as they are often a beginner in the field, skilled in just one coding language. Coders are usually given the job of writing forthright pieces of code that can easily be delegated by the developers. As some are put-off by the title, it is sometimes used interchangeably with “Junior Programmer” or “Junior Developer.”</p><h3 id="Developers-and-Programmers"><a href="#Developers-and-Programmers" class="headerlink" title="Developers and Programmers"></a>Developers and Programmers</h3><p>The titles Developer and programmer are often used interchangeably. They are more experienced code writers who are versed in at least two to three languages and write clean, error free codes. They can apply their algorithmic knowledge to create more sophisticated levels of software coding.</p><p>Developers in some firms are sometimes referred to as the start to finish overseers of a project, who are responsible for the overall design of the application.</p><h3 id="Software-Engineers"><a href="#Software-Engineers" class="headerlink" title="Software Engineers"></a>Software Engineers</h3><p>These are of the highest level among all, who are most expert coders around. They are well versed in three programming languages or more and use their skills to design and implement the overall architecture of the application. They modularize the final product to develop a clean interface and then work with the programmers and developers to implement the more detailed aspects of the design. An engineer position would usually imply that you are a developer who has a specific type of degree, some knowledge of engineering, and is capable of designing a system.</p><p>Now you know what do they do and whom should you approach, in case of any problem or help.</p><p>How does your organization differentiate between coders, programmers, developers, and engineers? Do you agree with the definitions above, or think otherwise, do let us know in the comments section below.</p>]]></content>
      
      
      <categories>
          
          <category> fun stuff </category>
          
      </categories>
      
      
        <tags>
            
            <tag> fun stuff </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>every principled coder should know</title>
      <link href="/2023/05/25/youtube_Coderize%E7%BC%96%E7%A8%8B%E8%A7%84%E8%8C%83/"/>
      <url>/2023/05/25/youtube_Coderize%E7%BC%96%E7%A8%8B%E8%A7%84%E8%8C%83/</url>
      
        <content type="html"><![CDATA[<ul><li><pre><code>Welcome the 7 deadly sins of programmingHi there, there are what I would consider to be seven deadly sins when it comes to programming.Things that will grind your code quality into dust if you don&#39;t heed their lessons.Now I hope you&#39;ve never had to hear someone tell you that you write bad code, but if youhave there&#39;s really nothing to be embarrassed about.We all write flawed code as we learn, and the good news is it&#39;s fairly straightforwardto make improvements if you&#39;re willing.In essence, that&#39;s why I&#39;ve created this video to guide you to becoming a better coder.So let&#39;s look at the mistakes you might be making and see if we can fix them.You should pick and use a standard, alwaysThe first thing I see people doing is not using programming standards.They give us rules to follow, like whitespacing, file structure and other philosophies thatwe apply to make our code consistent and therefore easily readable.It&#39;s also especially important when working with other people, because it allows everyoneto rely on shared expectations.If you don&#39;t keep standards, it&#39;s kind of like switching fonts all the time.We can read it, sure, but the subtle differences throw us off and slow us down a bit.As for choosing a standard, if you aren&#39;t given one by your team, then there&#39;s plentyto choose from in the wild.Principles are the lifeblood of programmersThe second thing, programming design principles, are probably some of my favourite ways toimprove.You can think of principles like a general guide into becoming a better programmer.They&#39;re the raw philosophies of code.Now there&#39;s a lot of principles out there, too many to cover in this video, but I willquickly show five very important ones which go under the acronym of SOLID.The S in SOLID stands for Single Responsibility, and it teaches us that we should aim to breakour code down into modules of one responsibility each.So if we have a big class that is performing unrelated jobs, for example, we should splitthat up into separate classes to avoid violating the principle.It&#39;s more code, yeah, but we can now easily identify what the class is trying to do, testit more cleanly and we can reuse parts of it elsewhere without having to worry aboutirrelevant methods at the same time.This actually becomes more important as we progress.The oh-so-open-closed principle suggests that we design our modules to be able to addnew functionality in the future without having to actually make changes to them.Instead, we should extend a module to add to it, be that wrapping it or something else,but we should never modify it directly.Once a module is in use, it&#39;s locked, and this now reduces the chances of any new additionsbreaking your code.Luckily, the Luminous Lyskov leaves us a lesson that loosely limits how we leverage our legacycode.Okay, that&#39;s enough of that.Lyskov wants to tell us that we should only extend modules when we&#39;re absolutely surethat it&#39;s still the same type at heart.For example, we can probably extend a hexagon into a six-pointed star, because that stillmakes sense as a six-sided shape, but we can&#39;t really do the same if we wanted a five orseven-pointed star, because that would no longer be compatible with what a hexagon represents.It just wouldn&#39;t fit cleanly anymore into parts of your code that expect hexagons, andso it will have failed the principle.If that&#39;s the case, it should extend something that fits its design or become its own typeinstead.Almost at the end now, and we have I for Interface Segregation.It says that our modules shouldn&#39;t need to know about functionality that they don&#39;t use.We need to split our modules into smaller abstractions, like interfaces, which we canthen compose to form an exact set of functionality that the module requires.This becomes especially useful when testing, as it allows us to mock out only the functionalitythat each module needs.Which brings me to Big D, which stands for Dependency Inversion.This one is pretty simple to explain, because it says that instead of talking to other partsof your code directly, we should always communicate abstractly, typically via the interfaces wedefine.Dependency Inversion breaks down any direct relationships between our code, and isolatesour modules completely from one another, meaning we can swap out parts as we need to.Because they communicate with interfaces now, they don&#39;t need to know what implementationthey are getting, only that they take certain inputs and return a valid output.The cool thing about SOLID is that when we combine all these principles together, itends up decoupling our code, giving us modules that are independent of each other and makingour code more maintainable, scalable, reusable and testable.Patterns let us learn from our programmer ancestorsProgramming design patterns, not to be confused with principles from the last chapter, arealso something I see underused a lot, when they really should have more of a place inyour mind.Patterns give us some real solutions to our code problems, but they aren&#39;t fixed implementations,so they&#39;re still kind of open to interpretation.We use them to architect our software systems, matching the right shapes to fit the needsour software has.First up, we have creational patterns, which are there to help us make and control newobject instances, such as the factory method pattern, which turns a bunch of requirementsinto different modules that follow the same interface, but aren&#39;t necessarily the sametype.Then there&#39;s structural patterns, which are concerned with how we organise and manipulateour objects, such as the adapter pattern, to wrap a module and adapt its interface toone that another module needs.Finally, there&#39;s behavioural patterns, which focus on how code functions and how it handlescommunication with other parts of the code, such as using the observer pattern to publishand subscribe to a stream of messages in an event-based sort of architecture.Now there&#39;s a bunch of different design patterns under each category, some of themyou might have used before.A lot of these patterns are used by frameworks and by professionals in huge corporations,and that kind of ties in with another pretty unique benefit.The benefit of creating a universal vocabulary of programming.Have you ever written some code that seemed great at the time, but later you had troubleNames are often badly... named?understanding it?Well, it often comes down to the way you name things.Take a look at this snippet.It&#39;s quite short, but it&#39;s hard to interpret what&#39;s going on without some thoughtful analysis.Let&#39;s fix this in steps.First up, we should avoid unnecessary encodings, such as type information, which make it harderto read code in a natural way.Next we have many abbreviations and acronyms that don&#39;t really explain well enough whatthey are.We should expand them to their full names to avoid any miscommunication.Something better, but it&#39;s not really clear what some of these variables hold.They&#39;re quite vague and ambiguous.We should aim to use names that more accurately represent the nuances of the code we&#39;re working with.We also want to replace magic values, such as the organ index or trigger word string,with named constants.By doing so, we clarify their significance, and we help to keep things in sync if theyused elsewhere.Okay, we can now read this code and understand what it&#39;s doing without having to thinktoo hard about it.However, we can still improve it further.If you have any compassion for your future self, or other unfortunate developers whomight have to read your code, be descriptive with your names.Ideally, we want to find a balance between being clear enough to quickly understand whatthe code does, without being so verbose that it becomes an information overload.Remember that no matter how good you think your code is, if it&#39;s not easy to read,I would argue that it&#39;s not actually good code at all.Tests give us confidenceMany people don&#39;t test their code, and that&#39;s understandable, I think.Writing tests can be very difficult when code is not properly architected.At the high level, we have end-to-end testing, which lets you test the system as if you werethe end user.It&#39;s useful because literally any spaghetti code can be end-to-end tested, assuming youcan simulate the inputs, as it never actually touches the code itself, only what it deliversto us.They can be tricky to set up, though, due to the need to always have a fully functionalapplication running, but they are surprisingly valuable.At the lower level, we have unit tests to verify the operation of our modules in isolation,and integration tests to examine the interaction between those modules.These provide validation that our code is doing what we expect it to, rather than focusingmore on behaviour, like end-to-end tests.If the thought of writing tests seems overwhelming right now, try applying the solid principlesyou learned earlier.You might be surprised at how much easier it becomes when your code is modular and decoupled.Time, the impossible enemyNumber six is…Time.And how you manage it.Time estimation is a process I still fail in sometimes.A common rule of thumb is to double or even triple your initial time estimate for a task.It feels excessive, but it&#39;s impossible to predict the unknown problems we will encounteralong the way, so we need to account for those.For example, this video took three times as long to make as I had predicted.I really should take my own advice sometimes.Remember that creation goes hand-in-hand with problems, so in the end, it&#39;s better tooverestimate and deliver ahead of schedule than it is to miss a deadline.Speed vs. productivity, what&#39;s better?Alright, this one is a bit cheeky, as it&#39;s still kind of related to time, but I neededseven, not six points to make the Deadly Sins reference, so here we are.All I wanted to say here is that you should try not to rush.Things can feel great when we&#39;re blazing through a project, and there&#39;s definitelya place for that in prototypes.But remember that if this is going to be a long-term project, take your time and thinkthings through from day one.We&#39;ll never get all our decisions right first time, but we can at least give ourselvesa better foundation to work from, and hopefully avoid some of that nasty code debt later.Anyway, you&#39;re likely to finish in less time regardless if you&#39;re not constantly battlingdecisions you can&#39;t easily fix because of poor architecture.We want projects that get easier with time, not harder.Leveling upAnd that&#39;s it.Wow, you leveled up.Go forth and be the programmer you were always meant to be.I&#39;d like to end with a quote from Martin Fowler.Any fool can write code that a computer can understand.Good programmers write code that humans can understand.Thank you so much for watching.It&#39;s been many weeks making this video, but it&#39;s all worth it to see that smile of yours</code></pre></li></ul>]]></content>
      
      
      <categories>
          
          <category> something you should know </category>
          
      </categories>
      
      
        <tags>
            
            <tag> something you should know </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>FBI Chris Voss Negotiation course</title>
      <link href="/2023/05/22/FBI%E9%A6%96%E5%B8%AD%E8%B0%88%E5%88%A4%E4%B8%93%E5%AE%B6-Chris%20Voss%20%E6%95%99%E8%B0%88%E5%88%A4%E5%A4%A7%E5%B8%88%E8%AF%BE/"/>
      <url>/2023/05/22/FBI%E9%A6%96%E5%B8%AD%E8%B0%88%E5%88%A4%E4%B8%93%E5%AE%B6-Chris%20Voss%20%E6%95%99%E8%B0%88%E5%88%A4%E5%A4%A7%E5%B8%88%E8%AF%BE/</url>
      
        <content type="html"><![CDATA[<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br></pre></td><td class="code"><pre><span class="line">第一课</span><br><span class="line"></span><br><span class="line">谈判：对手是谈判的局势，对面的人只是部分问题有争议，一起解决争议。</span><br><span class="line"></span><br><span class="line">战术同理心（情商）：全身心站在他人立场考虑问题。了解对方规则并尊重它，而不一定要接受规则。</span><br><span class="line"></span><br><span class="line">第二课 映射</span><br><span class="line"></span><br><span class="line">映射：找出可能成功的方法，让对方明确他们自身想法，觉得参与整个过程后希望和你达成协议。</span><br><span class="line"></span><br><span class="line"><span class="number">1.</span>映射方法来收集信息：通常重复一句话中一到三个词，对方觉得被倾听，因此会顺着我们思路走 。提出疑问后会使用过多的词语表达，会改变措辞。专注倾听后对方也不会因为话没说全而被责备。</span><br><span class="line"></span><br><span class="line"><span class="number">2.</span>映射来建立友好关系：对方喜欢被鼓励说更多的话，被映射后觉得你有趣，因此喜欢与你交谈。采用重复关键词并带疑问情绪效果更好。</span><br><span class="line"></span><br><span class="line"><span class="number">3.</span>映射对立方的话：商业谈判中映射可收集更多信息，要采用温和语调，充分好奇</span><br><span class="line"></span><br><span class="line"><span class="number">4.</span>沉默是金：使用映射后，通过沉默方式停顿下，让对方思考，并且是用我们的方式促使他们思考，直到说出更多信息。</span><br><span class="line"></span><br><span class="line"><span class="number">5.</span>坚持使用映射：从低成本事件练起，向需要学习的人练起，坚持后就可以熟练的使用。</span><br><span class="line"></span><br><span class="line">第三课 标注</span><br><span class="line"></span><br><span class="line"><span class="number">1.</span>标注情绪：意识到对方的情绪或动态，再简单标注。做成标签后，会引发对方沉思自身行为，以减少对应负面情绪。</span><br><span class="line"></span><br><span class="line">贴标签并建立联系来收集信息，以增加对对方基于信任后的影响。</span><br><span class="line"></span><br><span class="line"><span class="number">2.</span>如何不标注：“我听到的”是一种错误的标注，“我”字导致传达的信息-我对自己观点比你的更感兴趣。标注后控制谈论的冲动也很重要。等第一个标注深入人心后再提问或做第二个标注。</span><br><span class="line"></span><br><span class="line"><span class="number">3.</span>多次标注：标注后对方无反应正说明标注起作用，要做的是更多次的标注。</span><br><span class="line"></span><br><span class="line"><span class="number">4.</span>加强积极情绪：负面情绪标注会减少，正向情绪标注会加强。</span><br><span class="line"></span><br><span class="line"><span class="number">5.</span>串联映射和标注：重复映射会得到准确的标注，标注能得到你想拓展的信息。</span><br><span class="line"></span><br><span class="line">第四课 掌握传达信息的技巧</span><br><span class="line"></span><br><span class="line">内心声音背叛外在声音，通过语气、情绪的表达传达正确信息。</span><br><span class="line"></span><br><span class="line"><span class="number">1.</span>操控镜像神经元：被操控镜像神经元后，产生的是无意识反应。</span><br><span class="line"></span><br><span class="line">深夜调频DJ声音可击中神经元，减慢大脑反应，促使人冷静（直接说“冷静”是种命令，使人生厌）。附带“微笑”以积极方式触发神经元，让敌我都聪明，以便通过打动神经元来达成交易。</span><br><span class="line"></span><br><span class="line"><span class="number">2.</span>丢弃“专断”的声音：好斗的语气表示直爽、诚实，却总适得其反。愤怒在现实世界中总会留有负面，不利于长期关系的相处。（除非想终结这段谈判）</span><br><span class="line"></span><br><span class="line"><span class="number">3.</span>使用“调侃”的声音：调侃语气表达合作的想法，不让对方觉得咄咄逼人，我想确信这真相能轻轻的着陆。</span><br><span class="line"></span><br><span class="line"><span class="number">80</span>%的时间应使用调侃或调解者的声音，让人保持积极的心态，思考去与你合作 。</span><br><span class="line"></span><br><span class="line"><span class="number">4.</span>使用“分析师”声音：陈述性带有向下折的、缓慢的声音，以表达不可动摇的意见。诚实自信及偶而的分析师声音可让谈话慢下来，对方会觉得被冷处理，并不会对谈判中可能出现的变化充满激情，需要少而准确的使用。</span><br><span class="line"></span><br><span class="line"><span class="number">5.</span>“深夜电台主播”的声音：比“分析师”声音更温暖，在<span class="number">10</span>~<span class="number">20</span>%的时间使用可使不高兴的对方冷静下来。</span><br><span class="line"></span><br><span class="line"><span class="number">6.</span>变调：变调在可声明式的语句中添加好奇的语气，可让别人觉得顺从，尤其是末尾真心询问的语调，能帮助语言更好的着陆。</span><br><span class="line"></span><br><span class="line"><span class="number">7.</span>线上沟通：不过分依赖一种沟通方式，保持简短有效的沟通，避免负面解读可用词柔和，结尾积极。</span><br><span class="line"></span><br><span class="line">第五课 肢体语言及语言模式</span><br><span class="line"></span><br><span class="line">通过肢体语言及语气与内容不一致，来准确识别是否为谎言。需要了解情况的能力、注意力放在对面、其他人对自己的反应、对自己说话的反应</span><br><span class="line"></span><br><span class="line"><span class="number">1.7</span>/<span class="number">38</span>/<span class="number">55</span>法则：谈话组成<span class="number">7</span>%谈话内容重要性，<span class="number">38</span>%语气重要性，<span class="number">55</span>%肢体语言重要性。可判断对方是否真诚。可从肢体语言及语气入手。（例子：我听到了你说可以，但我从你的语气里听到了一些迟疑）</span><br><span class="line"></span><br><span class="line"><span class="number">2.</span>观察旁观者：群体谈判中，谈判者会认为注意力放在主要谈判人身上，场边人因过少受到关注，他们的肢体语言无防御机制会暴露真实想法。</span><br><span class="line"></span><br><span class="line"><span class="number">3.</span>确认基准线和偏离点：真话说出的方式只有一种，通过一些准绳问题（你叫什么，你在哪，今天星期几），了解说真话的基准线。开始使用战术同理心，让其舒适，找到基准线，再抛出问题。</span><br><span class="line"></span><br><span class="line"><span class="number">4.</span>匹诺曹效应：说谎时会想更努力地说服你，使用更多词语让你信服。</span><br><span class="line"></span><br><span class="line"><span class="number">5.</span>如何应付谎言：使用变调的语气表达不想合作的疑虑（标注），将对话从谎言中带出来（好奇语气）。说谎的原因首先是不敢说实话，对方在评估形势后提高警惕。使用深夜DJ声音去预测而不是评判，理解但不质疑，让对方了解可以为你放松警惕。</span><br><span class="line"></span><br><span class="line">第六课 制造掌控全场的幻觉</span><br><span class="line"></span><br><span class="line"><span class="number">1.</span>用“怎样和什么”来提问：给对方掌握大局的错觉。大部分使用“什么”和“怎样”来校准问题。“为什么”容易触发防御机制，让人觉得自己被指责。</span><br><span class="line"></span><br><span class="line"><span class="number">2.</span>通过提问强制引起共鸣：互惠关系并不能总起作用，不得不是对方重新审视问题。“这个情况下我该怎么做” ，让对方真正去考虑你正在经历什么。</span><br><span class="line"></span><br><span class="line"><span class="number">3.</span>通过校准问题去重塑对方思维： “这个情况下我该怎么做”是为了塑造对方的思维，让他们有同理心去考虑。“我该怎么做”“如果这样做会发生什么”“我该怎么应对这件事呢”三种不同方式提问会给对方三种角度去思考。</span><br><span class="line"></span><br><span class="line"><span class="number">4.</span>规避触发互惠机制：提问会让人有愧疚感，因为不想欠债。如果没准备好，就先不要询问问题。“怎样”的提问会把解决问题的责任抛给了对方。因为对方不觉得有负担，会以为自己掌握大局。</span><br><span class="line"></span><br><span class="line"><span class="number">5.</span>提出合理问题：“当我们达成协议后，我们将如何推进”“过去你是怎样和我这样的人交易的”“你过去是怎么做这笔交易的”合逻辑的问题是可以提问的，至少可以使他们停下并改变他们的思维方式。</span><br><span class="line"></span><br><span class="line">第七课 指控检查</span><br><span class="line"></span><br><span class="line">退后一步进行盘点，检查所有可能的负面影响。谩骂，指责，诽谤，对方会想到的基于当前条件下的所有我的事情。“我不想让你觉得我.....”基于过去的实验或生活得出负面影响。未表达的负面情绪永远不会消失。</span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> something you should know </category>
          
      </categories>
      
      
        <tags>
            
            <tag> something you should know </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>errors_solutions experience</title>
      <link href="/2023/05/21/%E6%89%80%E6%9C%89%E6%8A%A5%E9%94%99%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86%E6%96%B9%E6%B3%95/"/>
      <url>/2023/05/21/%E6%89%80%E6%9C%89%E6%8A%A5%E9%94%99%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86%E6%96%B9%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<p><a href="https://segmentfault.com/a/1190000021098910">how to upload big dataset to the server</a>  &#x2F;&#x2F; For me, I used  !wget in the colab or the notebook in the server. You definitely can use it solely in the ssh terminal though. &#x2F;&#x2F;</p><p><a href="https://zblogs.top/how-to-fix-telegram-for-mac-is-connecting-to-proxy/">It’s about how to connect TG on the laptop</a></p><p>find your anaconda(solve “zsh&#x2F;bash shell cannot find your conda) : if you are a macos user and already have the anaconda-navigator app, just find it in the “applications” in the findre, and right click it then open the original content folders. Then directly add this into your bash&#x2F;zsh shell configuration file, for exmaple, I use this line:<br><code>export PATH=/Users/anaconda3/bin:$PATH</code></p>]]></content>
      
      
      <categories>
          
          <category> something you should know </category>
          
      </categories>
      
      
        <tags>
            
            <tag> something you should know </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>C++ 南科大于仕琪老师</title>
      <link href="/2023/05/09/%E4%BA%8E%E4%BB%95%E7%90%AA%E8%80%81%E5%B8%88c++/"/>
      <url>/2023/05/09/%E4%BA%8E%E4%BB%95%E7%90%AA%E8%80%81%E5%B8%88c++/</url>
      
        <content type="html"><![CDATA[<h2 id="C-于老师课程随记-Courses-link"><a href="#C-于老师课程随记-Courses-link" class="headerlink" title="C++于老师课程随记 Courses link"></a>C++于老师课程随记 <a href="https://www.bilibili.com/video/BV1Vf4y1P7pq/?p=26&share_source=copy_web&vd_source=0da83c85e0b1f7f109629437b2cf54e7">Courses link</a></h2><p>###pointers and arrays</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// when pointer plus 1, it moves in 1 section/element(which depends on the pointer type) not 1 byte </span></span><br><span class="line"><span class="type">int</span> numbers[<span class="number">4</span>] = &#123;<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>&#125;;</span><br><span class="line"><span class="type">int</span> *p = numbers + <span class="number">1</span>;</span><br></pre></td></tr></table></figure><ul><li><p>32位机器地址位数32位即4bytes </p></li><li><p>64位机器地址位数64位即8bytes  </p></li><li><p>指针大小是由当前CPU运行模式的寻址位数决定</p></li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> numbers [<span class="number">4</span>] = &#123;<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>&#125;;</span><br><span class="line"><span class="type">int</span> *p = numbers; </span><br><span class="line">cout &lt;&lt; <span class="built_in">sizeof</span>(numbers) &lt;&lt; endl; <span class="comment">//4*sizeof(int)</span></span><br><span class="line">cout &lt;&lt; <span class="built_in">sizeof</span>(p) &lt;&lt; endl; <span class="comment">// 4 or 8</span></span><br><span class="line">cout &lt;&lt; <span class="built_in">sizeof</span>(<span class="type">double</span> *) &lt;&lt; endl; <span class="comment">// 4 or 8</span></span><br></pre></td></tr></table></figure><h3 id="dynamic-allocate-memory动态内存管理"><a href="#dynamic-allocate-memory动态内存管理" class="headerlink" title="dynamic allocate memory动态内存管理"></a>dynamic allocate memory动态内存管理</h3><p>…..</p><h3 id="Functions"><a href="#Functions" class="headerlink" title="Functions"></a>Functions</h3><ul><li><strong>pass by value</strong> will be a latency when the arguments being passed i nto are large, which will definitely cost consumption of computing resources.</li><li><strong>References</strong> : A reference must be initialized aftre its declaration.<br><code>int&amp; xxx_reference; // error</code><br><code>Any_type&amp; xxx_reference; // error</code><br>becaue they haven’t been initialized.(References are MUCH safer)</li><li><strong>Return statement</strong> : if the type of your function is <strong>void</strong>, you no longer need the “return” line.</li></ul><p><strong>e.g.</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">void print_text(string text)</span><br><span class="line">&#123;</span><br><span class="line">cout &lt;&lt; text &lt;&lt; endl;</span><br><span class="line">return; // you can delete this line.</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>good habit</strong> : when you are constructing a function, you should always check the parameters throughly to avoid some meaningless errors.</p><h3 id="inline-function"><a href="#inline-function" class="headerlink" title="inline function"></a>inline function</h3><p>can replace the current line with main body of the invoked function, which is a strategy to sacrifice space for time.</p><h3 id="Marcos"><a href="#Marcos" class="headerlink" title="Marcos"></a>Marcos</h3><p>is sort of a text replacement. It will use the defined text to replace the function call.</p><p>e.g.<code>#define xxx_MACRO(a, b) (a)&gt;(b) ? (a) : (b)  // do not ignore the parentheses here, which will cause  priority errors.</code></p><h3 id="default-arguments"><a href="#default-arguments" class="headerlink" title="default arguments"></a>default arguments</h3><p>can only be set from the tail, which means you can set the default arguments within the first one but without the later ones.</p><p><strong>e.g.</strong></p><p><code>float norm(float x, float y = 0, float z);</code> &#x2F;&#x2F; error</p><p>And avoid resetting the same arguments more than one time.</p><p><strong>e.g.</strong><br><code>float norm(float x, float y = 1, float z=1);</code> &#x2F;&#x2F;error b&#x2F;c y has been set at the first time.</p><h3 id="function-overloading"><a href="#function-overloading" class="headerlink" title="function overloading"></a>function overloading</h3><p>Function loading in c++ has a good feature, which is that you can use the same name to define few functions, but keep in mind that you should at lease change the types of the function return or parameters.</p><p><strong>e.g.</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">// the first function</span><br><span class="line">int get_sum(int first_number, int second_number)&#123;&#125;</span><br><span class="line"></span><br><span class="line">// the second function</span><br><span class="line">float get_sum(float first_number, float second_number&#123;&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="function-templates"><a href="#function-templates" class="headerlink" title="function templates"></a>function templates</h3><p>Templates are vitural concept, that means you should always instancialize instantiate it explicitly.</p><p><strong>e.g.</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;typeinfo&gt;</span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">template &lt;typename T&gt;</span><br><span class="line">T sum(T num1, T num2)</span><br><span class="line">&#123;</span><br><span class="line">return num1 + num2;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// instantiate</span><br><span class="line"></span><br><span class="line">template int sum(int, int); // that&#x27;s it.</span><br><span class="line">// or you can use other types.</span><br><span class="line">// template double sum(double, double);</span><br><span class="line"></span><br><span class="line">int main()</span><br><span class="line">&#123;</span><br><span class="line">auto result = sum(1, 1);</span><br><span class="line">cout &lt;&lt; result &lt;&lt; endl; // which should be 2 here</span><br><span class="line">return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="functions-pointers-x2F-references"><a href="#functions-pointers-x2F-references" class="headerlink" title="functions pointers&#x2F;references"></a>functions pointers&#x2F;references</h3>]]></content>
      
      
      <categories>
          
          <category> C++ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> C++ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>C++ learning record</title>
      <link href="/2023/04/30/c++_record/"/>
      <url>/2023/04/30/c++_record/</url>
      
        <content type="html"><![CDATA[<pre><code>                            ## C++个人笔记总结—王小龙读后笔记</code></pre><h3 id="基本点"><a href="#基本点" class="headerlink" title="基本点"></a>基本点</h3><p>C++是强类型语言，任何变量或函数遵循：先申明后使用的原则。同时它是静态语言：需要指定变量类型，编译速度快可靠性高。</p><p>操作符重载 函数重载</p><p>c++中结构与c不同：定义结构型变量时不用加struct关键字；结构内部可以定义成员函数；sizeof（结构）-》1</p><h3 id="内联-inline"><a href="#内联-inline" class="headerlink" title="内联 inline"></a>内联 inline</h3><p>C++ <strong>内联函数</strong>是通常与类一起使用。如果一个函数是内联的，那么在编译时，编译器会把该函数的代码副本放置在每个调用该函数的地方。</p><p>对内联函数进行任何修改，都需要重新编译函数的所有客户端，因为编译器需要重新更换一次所有的代码，否则将会继续使用旧的函数。</p><p>如果想把一个函数定义为内联函数，则需要在函数名前面放置关键字 <strong>inline</strong>，在调用函数之前需要对函数进行定义。如果已定义的函数多于一行，编译器会忽略 inline 限定符。</p><h3 id="c-的动态内存分配"><a href="#c-的动态内存分配" class="headerlink" title="c++的动态内存分配"></a>c++的动态内存分配</h3><p><a href="http://c.biancheng.net/view/206.html">http://c.biancheng.net/view/206.html</a></p><h3 id="C-之父的建议"><a href="#C-之父的建议" class="headerlink" title="C++之父的建议"></a>C++之父的建议</h3><p>1.少用宏，多用 const、enum 和 inline  原因：<a href="https://developer.aliyun.com/article/849684?spm=a2c6h.12873639.article-detail.29.71a47b95al0tZN&scm=20140722.ID_community">https://developer.aliyun.com/article/849684?spm=a2c6h.12873639.article-detail.29.71a47b95al0tZN&amp;scm=20140722.ID_community</a></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">define</span> PAI 3.141519</span></span><br><span class="line"><span class="type">const</span> <span class="type">double</span> PAI = <span class="number">3.14159</span>;</span><br><span class="line"><span class="meta">#<span class="keyword">define</span> ERROR_FILE -1</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> ERROR_MEM  -2</span></span><br><span class="line"><span class="keyword">enum</span> &#123;</span><br><span class="line">  ERROR_FILE = <span class="number">-1</span>,</span><br><span class="line">  ERROR_MEM = <span class="number">-2</span></span><br><span class="line">&#125;;</span><br><span class="line"><span class="meta">#<span class="keyword">define</span> max(a,b) ((a)&gt;(b)?(a):(b))</span></span><br><span class="line"><span class="function"><span class="keyword">inline</span> <span class="type">int</span> <span class="type">double</span> <span class="title">max</span> <span class="params">(<span class="type">double</span> a, <span class="type">double</span> b)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> a &gt; b ? a : b;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>2.变量随用随声明同时初始化。<br>3.少用 malloc&#x2F;free，多用 new&#x2F;delete。<a href="https://www.cnblogs.com/Allen-rg/p/6767182.html">https://www.cnblogs.com/Allen-rg/p/6767182.html</a><br>4.少用 C 风格的强制类型转换，多用类型转换运算符。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">double</span> d = <span class="number">3.14</span>;</span><br><span class="line"><span class="type">int</span> i = (<span class="type">int</span>)d;   <span class="comment">// C 风格的强制类型转换</span></span><br><span class="line"><span class="type">int</span> j = <span class="built_in">static_cast</span>&lt;<span class="type">int</span>&gt;(d);   <span class="comment">// 类型转换运算符</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>6.树立面向对象的编程思想。</p><h3 id="类和对象"><a href="#类和对象" class="headerlink" title="类和对象"></a>类和对象</h3><p>什么是对象</p><p>1.万物皆对象2.程序就是一组对象，对象之间通过消息交换信息3.类就是对对象的描述和抽象，对象就是类的具体化和实例化</p><p>通过类描述对象</p><p>属性:姓名、年龄、学号<br>行为:吃饭、睡觉、学习<br>类就是从属性和行为两个方面对对象进行抽象。</p><p>对象创建过程<br>分配内存-&gt;调用构造函数-&gt;调用类类型成员的构造函数-&gt;构造函数的代码</p><p>在一般情况下，堆的空间比栈大。栈是由编译器自动管理的内存空间，它的大小通常受限于操作系统或编译器的限制。而堆则是由程序员手动管理的内存空间，其大小取决于计算机的内存容量和操作系统对程序的内存使用限制。</p><p>在栈上分配的变量通常是局部变量，其生存期仅限于所在的函数调用过程中，一旦函数返回，变量所占用的内存就会被自动释放。而在堆上分配的变量则可以在整个程序的生命周期内使用，直到程序退出或被手动释放。</p><p>需要注意的是，由于堆的空间比较大，因此使用堆分配内存时需要注意内存泄漏和内存碎片等问题。而栈的空间虽然比较小，但由于其内存管理由编译器自动完成，因此使用栈分配内存时更加安全和简便。</p><p>类的声明与定义以及使用可以不在一个文件</p><p>如果同时有多种构造函数存在，则根据构造参数来确定调用哪个构造函数，既构造函数可 以通过构造参数实现重载<br>​<br>​<br>​</p>]]></content>
      
      
      <categories>
          
          <category> C++ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> C++ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ResearchGPT：Powerful tools for assisting you in reading research papers</title>
      <link href="/2023/04/28/Intro%20to%20ResearchGPT/"/>
      <url>/2023/04/28/Intro%20to%20ResearchGPT/</url>
      
        <content type="html"><![CDATA[<h1 id="ResearchGPT"><a href="#ResearchGPT" class="headerlink" title="ResearchGPT"></a>ResearchGPT</h1><p>This is a flask app provides an interface to enable a conversation with a research paper. You can enter a link to a pdf hoseted online or upload your own pdf. The app will then extract the text from the pdf, create embeddings from the ext and use them with the openai api to generate a response to a question you ask. It will also return a source for the part of the text it used to generate the response and the page number.</p><p>Try the demo at: <a href="https://www.dara.chat/">https://www.dara.chat</a></p><p>GitHub repo: <a href="https://github.com/mukulpatnaik/researchgpt">https://github.com/mukulpatnaik/researchgpt</a></p><h2 id="interface-be-like"><a href="#interface-be-like" class="headerlink" title="interface be like:"></a>interface be like:</h2><h2 id="Installation"><a href="#Installation" class="headerlink" title="Installation"></a>Installation</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git clone https://github.com/mukulpatnaik/researchgpt.git</span><br><span class="line">cd researchgpt</span><br><span class="line">pip install -r requirements.txt</span><br></pre></td></tr></table></figure><h2 id="Usage"><a href="#Usage" class="headerlink" title="Usage"></a>Usage</h2><p>You need to have an openai api key and set it as the environment variable ‘OPENAI_API_KEY’.</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python main-local.py</span><br></pre></td></tr></table></figure><h2 id="Google-Cloud-Deployment"><a href="#Google-Cloud-Deployment" class="headerlink" title="Google Cloud Deployment"></a>Google Cloud Deployment</h2><p>Follow the instructions here: <a href="https://cloud.google.com/appengine/docs/standard/python3/building-app/deploying-web-service">https://cloud.google.com/appengine/docs/standard/python3/building-app/deploying-web-service</a> Once you have the app.yaml file set up with your openai key and also have gcloud cli set up, you can deploy with:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gcloud app deploy</span><br></pre></td></tr></table></figure><p>To stream logs:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gcloud app logs tail</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Tools </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Tools </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
